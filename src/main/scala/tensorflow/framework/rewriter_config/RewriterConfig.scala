// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package tensorflow.framework.rewriter_config

import tensorflow.framework.attr_value.AttrValue
import tensorflow.framework.verifier_config.VerifierConfig
import tensorflow.framework.{attr_value, rewriter_config, verifier_config}

/** Graph rewriting is experimental and subject to change, not covered by any
  * API stability guarantees.
  *
  * @param cpuLayoutConversion
  *   CPU Conversion settings between NHCW and NCHW.
  * @param layoutOptimizer
  *   Optimize tensor layouts (default is ON)
  *   e.g. This will try to use NCHW layout on GPU which is faster.
  * @param constantFolding
  *   Fold constants (default is ON)
  *   Statically infer the value of tensors when possible, and materialize the
  *   result using constants.
  * @param shapeOptimization
  *   Shape optimizations (default is ON)
  *   Simplify computations made on shapes.
  * @param remapping
  *   Remapping (default is ON)
  *   Remap subgraphs onto more efficient implementations.
  * @param commonSubgraphElimination
  *   Common subgraph elimination (default is ON)
  *   e.g. Simplify arithmetic ops; merge ops with same value (like constants).
  * @param arithmeticOptimization
  *   Arithmetic optimizations (default is ON)
  *   e.g. Simplify arithmetic ops; merge ops with same value (like constants).
  * @param dependencyOptimization
  *   Control dependency optimizations (default is ON).
  *   Remove redundant control dependencies, which may enable other optimization.
  * @param loopOptimization
  *   Loop optimizations (default is ON).
  * @param functionOptimization
  *   Function optimizations (default is ON).
  * @param debugStripper
  *   Strips debug-related nodes from the graph (off by default).
  * @param disableModelPruning
  *   If true, don't remove unnecessary ops from the graph
  * @param scopedAllocatorOptimization
  *   Try to allocate some independent Op outputs contiguously in order to
  *   merge or eliminate downstream Ops (off by default).
  * @param pinToHostOptimization
  *   Force small ops onto the CPU (default is OFF).
  * @param implementationSelector
  *   Enable the swap of kernel implementations based on the device placement
  *   (default is ON).
  * @param autoMixedPrecision
  *   Optimize data types for CUDA/oneDNN (default is OFF).
  *   This will try to use float16 on GPU/CPU which is faster.
  *   Note that this can change the numerical stability of the graph and may
  *   require the use of loss scaling to maintain model convergence.
  * @param autoMixedPrecisionMkl
  *   Optimize data types for oneDNN (default is OFF).
  *   This will try to use bfloat16 on CPUs, which is faster.
  *   Note that this can change the numerical stability of the graph.
  *   Note: this is deprecated.
  *   It is replaced by auto_mixed_precision_onednn_bfloat16
  * @param autoMixedPrecisionOnednnBfloat16
  *   Optimize data types for oneDNN (default is OFF).
  *   This will try to use bfloat16 on CPUs, which is faster.
  *   Note that this can change the numerical stability of the graph.
  *   Note: this is equivalent to the deprecated option auto_mixed_precision_mkl
  * @param autoMixedPrecisionCpu
  *   Emulate a model using data type float16 on CPU (default is OFF).
  *   This will try to emulate the float16 inputs and outputs of an operator
  *   on CPU to have better correlation with float16 on GPU; however the
  *   computation in the operator is based on float32.
  *   Note that this can change the numerical stability of the graph.
  * @param disableMetaOptimizer
  *   Disable the entire meta optimizer (off by default).
  * @param disableTfgOptimizer
  *   Disable the TFG optimizer (off by default).
  * @param usePluginOptimizers
  *   Optimizers registered by plugin (default is ON)
  * @param experimentalConditionalCodeMotion
  *   Conditional code motion (default is ON).
  * @param metaOptimizerIterations
  *   Controls how many times we run the optimizers in meta optimizer (default
  *   is once).
  * @param minGraphNodes
  *   The minimum number of nodes in a graph to optimizer. For smaller graphs,
  *   optimization is skipped.
  *   0 means the system picks an appropriate number.
  *   &lt; 0 means do not skip optimization.
  * @param experimentalDisableCompressedTensorOptimization
  *   Disable optimizations that assume compressed tensors. Note that this flag
  *   is experimental and may be removed in the future.
  * @param experimentalDisableFoldingQuantizationEmulation
  *   Disable folding quantization emulation ops such as FakeQuantWithMinMax* and
  *   QuantizeAndDequantize*. Some compilers (e.g. the TF-to-tflite converter)
  *   have to extract quantization configs (e.g. min/max range, number of bits,
  *   and per-channel) from the quantization emulation ops. Note that this flag
  *   is experimental and may be removed in the future. See b/174138564 for more
  *   details.
  * @param memoryOptimization
  *   Configures memory optimization passes through the meta-optimizer. Has no
  *   effect on manually requested memory optimization passes in the optimizers
  *   field.
  * @param memoryOptimizerTargetNodeNameScope
  *   A node name scope for node names which are valid outputs of recomputations.
  *   Inputs to nodes that match this scope may be recomputed (subject either to
  *   manual annotation of those input nodes or to manual annotation and
  *   heuristics depending on memory_optimization), but the nodes themselves will
  *   not be recomputed. This matches any sub-scopes as well, meaning the scope
  *   can appear not just as a top-level scope. For example, if the value is
  *   "gradients/", the default, it will match node name "gradients/foo",
  *   "foo/gradients/bar", but not "foo_gradients/"
  * @param metaOptimizerTimeoutMs
  *   Maximum number of milliseconds to spend optimizing a single graph before
  *   timing out. If less than or equal to 0 (default value) the optimizer will
  *   never time out.
  * @param autoParallel
  *   Configures AutoParallel optimization passes either through the
  *   meta-optimizer or when manually specified through the optimizers field.
  * @param failOnOptimizerErrors
  *   If true, any optimization pass failing will cause the MetaOptimizer to
  *   stop with an error. By default - or when set to false, failing passes are
  *   skipped silently.
  * @param optimizers
  *   If non-empty, will use this as an alternative way to specify a list of
  *   optimizations to turn on and the order of the optimizations (replacing the
  *   meta-optimizer).
  *  
  *   Of the RewriterConfig options, only the AutoParallel configuration options
  *   (the auto_parallel field) apply to manually requested optimization passes
  *   ("autoparallel"). Memory optimization passes ("memory") invoked here are
  *   not configurable (in contrast to memory optimization passes through the
  *   meta-optimizer) and act only on manual op annotations.
  *  
  *   Custom optimizers (see custom_optimizers) that are not part of this
  *   schedule will be run after - in the order that they were specified.
  * @param customOptimizers
  *   list of CustomGraphOptimizers to apply.
  * @param interOptimizerVerifierConfig
  *   VerifierConfig specifying the verifiers to be run after every optimizer.
  * @param postOptimizationVerifierConfig
  *   VerifierConfig specifying the verifiers to be run at the end, after all
  *   optimizers have run.
  */
@SerialVersionUID(0L)
final case class RewriterConfig(
                                 cpuLayoutConversion: RewriterConfig.CpuLayout = rewriter_config.RewriterConfig.CpuLayout.NO_CONVERSION_ON_CPU,
                                 layoutOptimizer: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 constantFolding: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 shapeOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 remapping: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 commonSubgraphElimination: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 arithmeticOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 dependencyOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 loopOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 functionOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 debugStripper: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 disableModelPruning: _root_.scala.Boolean = false,
                                 scopedAllocatorOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 pinToHostOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 implementationSelector: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 autoMixedPrecision: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 autoMixedPrecisionMkl: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 autoMixedPrecisionOnednnBfloat16: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 autoMixedPrecisionCpu: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 disableMetaOptimizer: _root_.scala.Boolean = false,
                                 disableTfgOptimizer: _root_.scala.Boolean = false,
                                 usePluginOptimizers: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 experimentalConditionalCodeMotion: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT,
                                 metaOptimizerIterations: RewriterConfig.NumIterationsType = rewriter_config.RewriterConfig.NumIterationsType.DEFAULT_NUM_ITERS,
                                 minGraphNodes: _root_.scala.Int = 0,
                                 experimentalDisableCompressedTensorOptimization: _root_.scala.Boolean = false,
                                 experimentalDisableFoldingQuantizationEmulation: _root_.scala.Boolean = false,
                                 memoryOptimization: RewriterConfig.MemOptType = rewriter_config.RewriterConfig.MemOptType.DEFAULT_MEM_OPT,
                                 memoryOptimizerTargetNodeNameScope: _root_.scala.Predef.String = "",
                                 metaOptimizerTimeoutMs: _root_.scala.Long = 0L,
                                 autoParallel: _root_.scala.Option[AutoParallelOptions] = _root_.scala.None,
                                 failOnOptimizerErrors: _root_.scala.Boolean = false,
                                 scopedAllocatorOpts: _root_.scala.Option[ScopedAllocatorOptions] = _root_.scala.None,
                                 optimizers: _root_.scala.Seq[_root_.scala.Predef.String] = _root_.scala.Seq.empty,
                                 customOptimizers: _root_.scala.Seq[RewriterConfig.CustomGraphOptimizer] = _root_.scala.Seq.empty,
                                 interOptimizerVerifierConfig: _root_.scala.Option[VerifierConfig] = _root_.scala.None,
                                 postOptimizationVerifierConfig: _root_.scala.Option[VerifierConfig] = _root_.scala.None,
                                 unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[RewriterConfig] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = cpuLayoutConversion.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(50, __value)
        }
      };
      
      {
        val __value = layoutOptimizer.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(1, __value)
        }
      };
      
      {
        val __value = constantFolding.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(3, __value)
        }
      };
      
      {
        val __value = shapeOptimization.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(13, __value)
        }
      };
      
      {
        val __value = remapping.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(14, __value)
        }
      };
      
      {
        val __value = commonSubgraphElimination.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(24, __value)
        }
      };
      
      {
        val __value = arithmeticOptimization.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(7, __value)
        }
      };
      
      {
        val __value = dependencyOptimization.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(8, __value)
        }
      };
      
      {
        val __value = loopOptimization.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(9, __value)
        }
      };
      
      {
        val __value = functionOptimization.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(10, __value)
        }
      };
      
      {
        val __value = debugStripper.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(11, __value)
        }
      };
      
      {
        val __value = disableModelPruning
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(2, __value)
        }
      };
      
      {
        val __value = scopedAllocatorOptimization.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(15, __value)
        }
      };
      
      {
        val __value = pinToHostOptimization.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(18, __value)
        }
      };
      
      {
        val __value = implementationSelector.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(22, __value)
        }
      };
      
      {
        val __value = autoMixedPrecision.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(23, __value)
        }
      };
      
      {
        val __value = autoMixedPrecisionMkl.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(25, __value)
        }
      };
      
      {
        val __value = autoMixedPrecisionOnednnBfloat16.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(31, __value)
        }
      };
      
      {
        val __value = autoMixedPrecisionCpu.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(29, __value)
        }
      };
      
      {
        val __value = disableMetaOptimizer
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(19, __value)
        }
      };
      
      {
        val __value = disableTfgOptimizer
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(32, __value)
        }
      };
      
      {
        val __value = usePluginOptimizers.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(28, __value)
        }
      };
      
      {
        val __value = experimentalConditionalCodeMotion.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(30, __value)
        }
      };
      
      {
        val __value = metaOptimizerIterations.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(12, __value)
        }
      };
      
      {
        val __value = minGraphNodes
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(17, __value)
        }
      };
      
      {
        val __value = experimentalDisableCompressedTensorOptimization
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(26, __value)
        }
      };
      
      {
        val __value = experimentalDisableFoldingQuantizationEmulation
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(27, __value)
        }
      };
      
      {
        val __value = memoryOptimization.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(4, __value)
        }
      };
      
      {
        val __value = memoryOptimizerTargetNodeNameScope
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(6, __value)
        }
      };
      
      {
        val __value = metaOptimizerTimeoutMs
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(20, __value)
        }
      };
      if (autoParallel.isDefined) {
        val __value = autoParallel.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      
      {
        val __value = failOnOptimizerErrors
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(21, __value)
        }
      };
      if (scopedAllocatorOpts.isDefined) {
        val __value = scopedAllocatorOpts.get
        __size += 2 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      optimizers.foreach { __item =>
        val __value = __item
        __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(100, __value)
      }
      customOptimizers.foreach { __item =>
        val __value = __item
        __size += 2 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      if (interOptimizerVerifierConfig.isDefined) {
        val __value = interOptimizerVerifierConfig.get
        __size += 2 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (postOptimizationVerifierConfig.isDefined) {
        val __value = postOptimizationVerifierConfig.get
        __size += 2 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = layoutOptimizer.value
        if (__v != 0) {
          _output__.writeEnum(1, __v)
        }
      };
      {
        val __v = disableModelPruning
        if (__v != false) {
          _output__.writeBool(2, __v)
        }
      };
      {
        val __v = constantFolding.value
        if (__v != 0) {
          _output__.writeEnum(3, __v)
        }
      };
      {
        val __v = memoryOptimization.value
        if (__v != 0) {
          _output__.writeEnum(4, __v)
        }
      };
      autoParallel.foreach { __v =>
        val __m = __v
        _output__.writeTag(5, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      {
        val __v = memoryOptimizerTargetNodeNameScope
        if (!__v.isEmpty) {
          _output__.writeString(6, __v)
        }
      };
      {
        val __v = arithmeticOptimization.value
        if (__v != 0) {
          _output__.writeEnum(7, __v)
        }
      };
      {
        val __v = dependencyOptimization.value
        if (__v != 0) {
          _output__.writeEnum(8, __v)
        }
      };
      {
        val __v = loopOptimization.value
        if (__v != 0) {
          _output__.writeEnum(9, __v)
        }
      };
      {
        val __v = functionOptimization.value
        if (__v != 0) {
          _output__.writeEnum(10, __v)
        }
      };
      {
        val __v = debugStripper.value
        if (__v != 0) {
          _output__.writeEnum(11, __v)
        }
      };
      {
        val __v = metaOptimizerIterations.value
        if (__v != 0) {
          _output__.writeEnum(12, __v)
        }
      };
      {
        val __v = shapeOptimization.value
        if (__v != 0) {
          _output__.writeEnum(13, __v)
        }
      };
      {
        val __v = remapping.value
        if (__v != 0) {
          _output__.writeEnum(14, __v)
        }
      };
      {
        val __v = scopedAllocatorOptimization.value
        if (__v != 0) {
          _output__.writeEnum(15, __v)
        }
      };
      scopedAllocatorOpts.foreach { __v =>
        val __m = __v
        _output__.writeTag(16, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      {
        val __v = minGraphNodes
        if (__v != 0) {
          _output__.writeInt32(17, __v)
        }
      };
      {
        val __v = pinToHostOptimization.value
        if (__v != 0) {
          _output__.writeEnum(18, __v)
        }
      };
      {
        val __v = disableMetaOptimizer
        if (__v != false) {
          _output__.writeBool(19, __v)
        }
      };
      {
        val __v = metaOptimizerTimeoutMs
        if (__v != 0L) {
          _output__.writeInt64(20, __v)
        }
      };
      {
        val __v = failOnOptimizerErrors
        if (__v != false) {
          _output__.writeBool(21, __v)
        }
      };
      {
        val __v = implementationSelector.value
        if (__v != 0) {
          _output__.writeEnum(22, __v)
        }
      };
      {
        val __v = autoMixedPrecision.value
        if (__v != 0) {
          _output__.writeEnum(23, __v)
        }
      };
      {
        val __v = commonSubgraphElimination.value
        if (__v != 0) {
          _output__.writeEnum(24, __v)
        }
      };
      {
        val __v = autoMixedPrecisionMkl.value
        if (__v != 0) {
          _output__.writeEnum(25, __v)
        }
      };
      {
        val __v = experimentalDisableCompressedTensorOptimization
        if (__v != false) {
          _output__.writeBool(26, __v)
        }
      };
      {
        val __v = experimentalDisableFoldingQuantizationEmulation
        if (__v != false) {
          _output__.writeBool(27, __v)
        }
      };
      {
        val __v = usePluginOptimizers.value
        if (__v != 0) {
          _output__.writeEnum(28, __v)
        }
      };
      {
        val __v = autoMixedPrecisionCpu.value
        if (__v != 0) {
          _output__.writeEnum(29, __v)
        }
      };
      {
        val __v = experimentalConditionalCodeMotion.value
        if (__v != 0) {
          _output__.writeEnum(30, __v)
        }
      };
      {
        val __v = autoMixedPrecisionOnednnBfloat16.value
        if (__v != 0) {
          _output__.writeEnum(31, __v)
        }
      };
      {
        val __v = disableTfgOptimizer
        if (__v != false) {
          _output__.writeBool(32, __v)
        }
      };
      {
        val __v = cpuLayoutConversion.value
        if (__v != 0) {
          _output__.writeEnum(50, __v)
        }
      };
      optimizers.foreach { __v =>
        val __m = __v
        _output__.writeString(100, __m)
      };
      customOptimizers.foreach { __v =>
        val __m = __v
        _output__.writeTag(200, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      interOptimizerVerifierConfig.foreach { __v =>
        val __m = __v
        _output__.writeTag(300, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      postOptimizationVerifierConfig.foreach { __v =>
        val __m = __v
        _output__.writeTag(301, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      unknownFields.writeTo(_output__)
    }
    def withCpuLayoutConversion(__v: RewriterConfig.CpuLayout): RewriterConfig = copy(cpuLayoutConversion = __v)
    def withLayoutOptimizer(__v: RewriterConfig.Toggle): RewriterConfig = copy(layoutOptimizer = __v)
    def withConstantFolding(__v: RewriterConfig.Toggle): RewriterConfig = copy(constantFolding = __v)
    def withShapeOptimization(__v: RewriterConfig.Toggle): RewriterConfig = copy(shapeOptimization = __v)
    def withRemapping(__v: RewriterConfig.Toggle): RewriterConfig = copy(remapping = __v)
    def withCommonSubgraphElimination(__v: RewriterConfig.Toggle): RewriterConfig = copy(commonSubgraphElimination = __v)
    def withArithmeticOptimization(__v: RewriterConfig.Toggle): RewriterConfig = copy(arithmeticOptimization = __v)
    def withDependencyOptimization(__v: RewriterConfig.Toggle): RewriterConfig = copy(dependencyOptimization = __v)
    def withLoopOptimization(__v: RewriterConfig.Toggle): RewriterConfig = copy(loopOptimization = __v)
    def withFunctionOptimization(__v: RewriterConfig.Toggle): RewriterConfig = copy(functionOptimization = __v)
    def withDebugStripper(__v: RewriterConfig.Toggle): RewriterConfig = copy(debugStripper = __v)
    def withDisableModelPruning(__v: _root_.scala.Boolean): RewriterConfig = copy(disableModelPruning = __v)
    def withScopedAllocatorOptimization(__v: RewriterConfig.Toggle): RewriterConfig = copy(scopedAllocatorOptimization = __v)
    def withPinToHostOptimization(__v: RewriterConfig.Toggle): RewriterConfig = copy(pinToHostOptimization = __v)
    def withImplementationSelector(__v: RewriterConfig.Toggle): RewriterConfig = copy(implementationSelector = __v)
    def withAutoMixedPrecision(__v: RewriterConfig.Toggle): RewriterConfig = copy(autoMixedPrecision = __v)
    def withAutoMixedPrecisionMkl(__v: RewriterConfig.Toggle): RewriterConfig = copy(autoMixedPrecisionMkl = __v)
    def withAutoMixedPrecisionOnednnBfloat16(__v: RewriterConfig.Toggle): RewriterConfig = copy(autoMixedPrecisionOnednnBfloat16 = __v)
    def withAutoMixedPrecisionCpu(__v: RewriterConfig.Toggle): RewriterConfig = copy(autoMixedPrecisionCpu = __v)
    def withDisableMetaOptimizer(__v: _root_.scala.Boolean): RewriterConfig = copy(disableMetaOptimizer = __v)
    def withDisableTfgOptimizer(__v: _root_.scala.Boolean): RewriterConfig = copy(disableTfgOptimizer = __v)
    def withUsePluginOptimizers(__v: RewriterConfig.Toggle): RewriterConfig = copy(usePluginOptimizers = __v)
    def withExperimentalConditionalCodeMotion(__v: RewriterConfig.Toggle): RewriterConfig = copy(experimentalConditionalCodeMotion = __v)
    def withMetaOptimizerIterations(__v: RewriterConfig.NumIterationsType): RewriterConfig = copy(metaOptimizerIterations = __v)
    def withMinGraphNodes(__v: _root_.scala.Int): RewriterConfig = copy(minGraphNodes = __v)
    def withExperimentalDisableCompressedTensorOptimization(__v: _root_.scala.Boolean): RewriterConfig = copy(experimentalDisableCompressedTensorOptimization = __v)
    def withExperimentalDisableFoldingQuantizationEmulation(__v: _root_.scala.Boolean): RewriterConfig = copy(experimentalDisableFoldingQuantizationEmulation = __v)
    def withMemoryOptimization(__v: RewriterConfig.MemOptType): RewriterConfig = copy(memoryOptimization = __v)
    def withMemoryOptimizerTargetNodeNameScope(__v: _root_.scala.Predef.String): RewriterConfig = copy(memoryOptimizerTargetNodeNameScope = __v)
    def withMetaOptimizerTimeoutMs(__v: _root_.scala.Long): RewriterConfig = copy(metaOptimizerTimeoutMs = __v)
    def getAutoParallel: AutoParallelOptions = autoParallel.getOrElse(rewriter_config.AutoParallelOptions.defaultInstance)
    def clearAutoParallel: RewriterConfig = copy(autoParallel = _root_.scala.None)
    def withAutoParallel(__v: AutoParallelOptions): RewriterConfig = copy(autoParallel = Option(__v))
    def withFailOnOptimizerErrors(__v: _root_.scala.Boolean): RewriterConfig = copy(failOnOptimizerErrors = __v)
    def getScopedAllocatorOpts: ScopedAllocatorOptions = scopedAllocatorOpts.getOrElse(rewriter_config.ScopedAllocatorOptions.defaultInstance)
    def clearScopedAllocatorOpts: RewriterConfig = copy(scopedAllocatorOpts = _root_.scala.None)
    def withScopedAllocatorOpts(__v: ScopedAllocatorOptions): RewriterConfig = copy(scopedAllocatorOpts = Option(__v))
    def clearOptimizers = copy(optimizers = _root_.scala.Seq.empty)
    def addOptimizers(__vs: _root_.scala.Predef.String *): RewriterConfig = addAllOptimizers(__vs)
    def addAllOptimizers(__vs: Iterable[_root_.scala.Predef.String]): RewriterConfig = copy(optimizers = optimizers ++ __vs)
    def withOptimizers(__v: _root_.scala.Seq[_root_.scala.Predef.String]): RewriterConfig = copy(optimizers = __v)
    def clearCustomOptimizers = copy(customOptimizers = _root_.scala.Seq.empty)
    def addCustomOptimizers(__vs: RewriterConfig.CustomGraphOptimizer *): RewriterConfig = addAllCustomOptimizers(__vs)
    def addAllCustomOptimizers(__vs: Iterable[RewriterConfig.CustomGraphOptimizer]): RewriterConfig = copy(customOptimizers = customOptimizers ++ __vs)
    def withCustomOptimizers(__v: _root_.scala.Seq[RewriterConfig.CustomGraphOptimizer]): RewriterConfig = copy(customOptimizers = __v)
    def getInterOptimizerVerifierConfig: VerifierConfig = interOptimizerVerifierConfig.getOrElse(verifier_config.VerifierConfig.defaultInstance)
    def clearInterOptimizerVerifierConfig: RewriterConfig = copy(interOptimizerVerifierConfig = _root_.scala.None)
    def withInterOptimizerVerifierConfig(__v: VerifierConfig): RewriterConfig = copy(interOptimizerVerifierConfig = Option(__v))
    def getPostOptimizationVerifierConfig: VerifierConfig = postOptimizationVerifierConfig.getOrElse(verifier_config.VerifierConfig.defaultInstance)
    def clearPostOptimizationVerifierConfig: RewriterConfig = copy(postOptimizationVerifierConfig = _root_.scala.None)
    def withPostOptimizationVerifierConfig(__v: VerifierConfig): RewriterConfig = copy(postOptimizationVerifierConfig = Option(__v))
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 50 => {
          val __t = cpuLayoutConversion.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 1 => {
          val __t = layoutOptimizer.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 3 => {
          val __t = constantFolding.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 13 => {
          val __t = shapeOptimization.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 14 => {
          val __t = remapping.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 24 => {
          val __t = commonSubgraphElimination.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 7 => {
          val __t = arithmeticOptimization.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 8 => {
          val __t = dependencyOptimization.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 9 => {
          val __t = loopOptimization.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 10 => {
          val __t = functionOptimization.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 11 => {
          val __t = debugStripper.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 2 => {
          val __t = disableModelPruning
          if (__t != false) __t else null
        }
        case 15 => {
          val __t = scopedAllocatorOptimization.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 18 => {
          val __t = pinToHostOptimization.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 22 => {
          val __t = implementationSelector.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 23 => {
          val __t = autoMixedPrecision.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 25 => {
          val __t = autoMixedPrecisionMkl.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 31 => {
          val __t = autoMixedPrecisionOnednnBfloat16.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 29 => {
          val __t = autoMixedPrecisionCpu.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 19 => {
          val __t = disableMetaOptimizer
          if (__t != false) __t else null
        }
        case 32 => {
          val __t = disableTfgOptimizer
          if (__t != false) __t else null
        }
        case 28 => {
          val __t = usePluginOptimizers.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 30 => {
          val __t = experimentalConditionalCodeMotion.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 12 => {
          val __t = metaOptimizerIterations.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 17 => {
          val __t = minGraphNodes
          if (__t != 0) __t else null
        }
        case 26 => {
          val __t = experimentalDisableCompressedTensorOptimization
          if (__t != false) __t else null
        }
        case 27 => {
          val __t = experimentalDisableFoldingQuantizationEmulation
          if (__t != false) __t else null
        }
        case 4 => {
          val __t = memoryOptimization.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 6 => {
          val __t = memoryOptimizerTargetNodeNameScope
          if (__t != "") __t else null
        }
        case 20 => {
          val __t = metaOptimizerTimeoutMs
          if (__t != 0L) __t else null
        }
        case 5 => autoParallel.orNull
        case 21 => {
          val __t = failOnOptimizerErrors
          if (__t != false) __t else null
        }
        case 16 => scopedAllocatorOpts.orNull
        case 100 => optimizers
        case 200 => customOptimizers
        case 300 => interOptimizerVerifierConfig.orNull
        case 301 => postOptimizationVerifierConfig.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 50 => _root_.scalapb.descriptors.PEnum(cpuLayoutConversion.scalaValueDescriptor)
        case 1 => _root_.scalapb.descriptors.PEnum(layoutOptimizer.scalaValueDescriptor)
        case 3 => _root_.scalapb.descriptors.PEnum(constantFolding.scalaValueDescriptor)
        case 13 => _root_.scalapb.descriptors.PEnum(shapeOptimization.scalaValueDescriptor)
        case 14 => _root_.scalapb.descriptors.PEnum(remapping.scalaValueDescriptor)
        case 24 => _root_.scalapb.descriptors.PEnum(commonSubgraphElimination.scalaValueDescriptor)
        case 7 => _root_.scalapb.descriptors.PEnum(arithmeticOptimization.scalaValueDescriptor)
        case 8 => _root_.scalapb.descriptors.PEnum(dependencyOptimization.scalaValueDescriptor)
        case 9 => _root_.scalapb.descriptors.PEnum(loopOptimization.scalaValueDescriptor)
        case 10 => _root_.scalapb.descriptors.PEnum(functionOptimization.scalaValueDescriptor)
        case 11 => _root_.scalapb.descriptors.PEnum(debugStripper.scalaValueDescriptor)
        case 2 => _root_.scalapb.descriptors.PBoolean(disableModelPruning)
        case 15 => _root_.scalapb.descriptors.PEnum(scopedAllocatorOptimization.scalaValueDescriptor)
        case 18 => _root_.scalapb.descriptors.PEnum(pinToHostOptimization.scalaValueDescriptor)
        case 22 => _root_.scalapb.descriptors.PEnum(implementationSelector.scalaValueDescriptor)
        case 23 => _root_.scalapb.descriptors.PEnum(autoMixedPrecision.scalaValueDescriptor)
        case 25 => _root_.scalapb.descriptors.PEnum(autoMixedPrecisionMkl.scalaValueDescriptor)
        case 31 => _root_.scalapb.descriptors.PEnum(autoMixedPrecisionOnednnBfloat16.scalaValueDescriptor)
        case 29 => _root_.scalapb.descriptors.PEnum(autoMixedPrecisionCpu.scalaValueDescriptor)
        case 19 => _root_.scalapb.descriptors.PBoolean(disableMetaOptimizer)
        case 32 => _root_.scalapb.descriptors.PBoolean(disableTfgOptimizer)
        case 28 => _root_.scalapb.descriptors.PEnum(usePluginOptimizers.scalaValueDescriptor)
        case 30 => _root_.scalapb.descriptors.PEnum(experimentalConditionalCodeMotion.scalaValueDescriptor)
        case 12 => _root_.scalapb.descriptors.PEnum(metaOptimizerIterations.scalaValueDescriptor)
        case 17 => _root_.scalapb.descriptors.PInt(minGraphNodes)
        case 26 => _root_.scalapb.descriptors.PBoolean(experimentalDisableCompressedTensorOptimization)
        case 27 => _root_.scalapb.descriptors.PBoolean(experimentalDisableFoldingQuantizationEmulation)
        case 4 => _root_.scalapb.descriptors.PEnum(memoryOptimization.scalaValueDescriptor)
        case 6 => _root_.scalapb.descriptors.PString(memoryOptimizerTargetNodeNameScope)
        case 20 => _root_.scalapb.descriptors.PLong(metaOptimizerTimeoutMs)
        case 5 => autoParallel.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 21 => _root_.scalapb.descriptors.PBoolean(failOnOptimizerErrors)
        case 16 => scopedAllocatorOpts.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 100 => _root_.scalapb.descriptors.PRepeated(optimizers.iterator.map(_root_.scalapb.descriptors.PString(_)).toVector)
        case 200 => _root_.scalapb.descriptors.PRepeated(customOptimizers.iterator.map(_.toPMessage).toVector)
        case 300 => interOptimizerVerifierConfig.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 301 => postOptimizationVerifierConfig.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: RewriterConfig.type = rewriter_config.RewriterConfig
    // @@protoc_insertion_point(GeneratedMessage[tensorboard.RewriterConfig])
}

object RewriterConfig extends scalapb.GeneratedMessageCompanion[RewriterConfig] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[RewriterConfig] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): RewriterConfig = {
    var __cpuLayoutConversion: RewriterConfig.CpuLayout = rewriter_config.RewriterConfig.CpuLayout.NO_CONVERSION_ON_CPU
    var __layoutOptimizer: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __constantFolding: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __shapeOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __remapping: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __commonSubgraphElimination: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __arithmeticOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __dependencyOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __loopOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __functionOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __debugStripper: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __disableModelPruning: _root_.scala.Boolean = false
    var __scopedAllocatorOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __pinToHostOptimization: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __implementationSelector: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __autoMixedPrecision: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __autoMixedPrecisionMkl: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __autoMixedPrecisionOnednnBfloat16: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __autoMixedPrecisionCpu: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __disableMetaOptimizer: _root_.scala.Boolean = false
    var __disableTfgOptimizer: _root_.scala.Boolean = false
    var __usePluginOptimizers: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __experimentalConditionalCodeMotion: RewriterConfig.Toggle = rewriter_config.RewriterConfig.Toggle.DEFAULT
    var __metaOptimizerIterations: RewriterConfig.NumIterationsType = rewriter_config.RewriterConfig.NumIterationsType.DEFAULT_NUM_ITERS
    var __minGraphNodes: _root_.scala.Int = 0
    var __experimentalDisableCompressedTensorOptimization: _root_.scala.Boolean = false
    var __experimentalDisableFoldingQuantizationEmulation: _root_.scala.Boolean = false
    var __memoryOptimization: RewriterConfig.MemOptType = rewriter_config.RewriterConfig.MemOptType.DEFAULT_MEM_OPT
    var __memoryOptimizerTargetNodeNameScope: _root_.scala.Predef.String = ""
    var __metaOptimizerTimeoutMs: _root_.scala.Long = 0L
    var __autoParallel: _root_.scala.Option[AutoParallelOptions] = _root_.scala.None
    var __failOnOptimizerErrors: _root_.scala.Boolean = false
    var __scopedAllocatorOpts: _root_.scala.Option[ScopedAllocatorOptions] = _root_.scala.None
    val __optimizers: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String] = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Predef.String]
    val __customOptimizers: _root_.scala.collection.immutable.VectorBuilder[RewriterConfig.CustomGraphOptimizer] = new _root_.scala.collection.immutable.VectorBuilder[RewriterConfig.CustomGraphOptimizer]
    var __interOptimizerVerifierConfig: _root_.scala.Option[VerifierConfig] = _root_.scala.None
    var __postOptimizationVerifierConfig: _root_.scala.Option[VerifierConfig] = _root_.scala.None
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 400 =>
          __cpuLayoutConversion = rewriter_config.RewriterConfig.CpuLayout.fromValue(_input__.readEnum())
        case 8 =>
          __layoutOptimizer = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 24 =>
          __constantFolding = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 104 =>
          __shapeOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 112 =>
          __remapping = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 192 =>
          __commonSubgraphElimination = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 56 =>
          __arithmeticOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 64 =>
          __dependencyOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 72 =>
          __loopOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 80 =>
          __functionOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 88 =>
          __debugStripper = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 16 =>
          __disableModelPruning = _input__.readBool()
        case 120 =>
          __scopedAllocatorOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 144 =>
          __pinToHostOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 176 =>
          __implementationSelector = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 184 =>
          __autoMixedPrecision = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 200 =>
          __autoMixedPrecisionMkl = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 248 =>
          __autoMixedPrecisionOnednnBfloat16 = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 232 =>
          __autoMixedPrecisionCpu = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 152 =>
          __disableMetaOptimizer = _input__.readBool()
        case 256 =>
          __disableTfgOptimizer = _input__.readBool()
        case 224 =>
          __usePluginOptimizers = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 240 =>
          __experimentalConditionalCodeMotion = rewriter_config.RewriterConfig.Toggle.fromValue(_input__.readEnum())
        case 96 =>
          __metaOptimizerIterations = rewriter_config.RewriterConfig.NumIterationsType.fromValue(_input__.readEnum())
        case 136 =>
          __minGraphNodes = _input__.readInt32()
        case 208 =>
          __experimentalDisableCompressedTensorOptimization = _input__.readBool()
        case 216 =>
          __experimentalDisableFoldingQuantizationEmulation = _input__.readBool()
        case 32 =>
          __memoryOptimization = rewriter_config.RewriterConfig.MemOptType.fromValue(_input__.readEnum())
        case 50 =>
          __memoryOptimizerTargetNodeNameScope = _input__.readStringRequireUtf8()
        case 160 =>
          __metaOptimizerTimeoutMs = _input__.readInt64()
        case 42 =>
          __autoParallel = _root_.scala.Option(__autoParallel.fold(_root_.scalapb.LiteParser.readMessage[AutoParallelOptions](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 168 =>
          __failOnOptimizerErrors = _input__.readBool()
        case 130 =>
          __scopedAllocatorOpts = _root_.scala.Option(__scopedAllocatorOpts.fold(_root_.scalapb.LiteParser.readMessage[ScopedAllocatorOptions](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 802 =>
          __optimizers += _input__.readStringRequireUtf8()
        case 1602 =>
          __customOptimizers += _root_.scalapb.LiteParser.readMessage[RewriterConfig.CustomGraphOptimizer](_input__)
        case 2402 =>
          __interOptimizerVerifierConfig = _root_.scala.Option(__interOptimizerVerifierConfig.fold(_root_.scalapb.LiteParser.readMessage[VerifierConfig](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 2410 =>
          __postOptimizationVerifierConfig = _root_.scala.Option(__postOptimizationVerifierConfig.fold(_root_.scalapb.LiteParser.readMessage[VerifierConfig](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    RewriterConfig(
        cpuLayoutConversion = __cpuLayoutConversion,
        layoutOptimizer = __layoutOptimizer,
        constantFolding = __constantFolding,
        shapeOptimization = __shapeOptimization,
        remapping = __remapping,
        commonSubgraphElimination = __commonSubgraphElimination,
        arithmeticOptimization = __arithmeticOptimization,
        dependencyOptimization = __dependencyOptimization,
        loopOptimization = __loopOptimization,
        functionOptimization = __functionOptimization,
        debugStripper = __debugStripper,
        disableModelPruning = __disableModelPruning,
        scopedAllocatorOptimization = __scopedAllocatorOptimization,
        pinToHostOptimization = __pinToHostOptimization,
        implementationSelector = __implementationSelector,
        autoMixedPrecision = __autoMixedPrecision,
        autoMixedPrecisionMkl = __autoMixedPrecisionMkl,
        autoMixedPrecisionOnednnBfloat16 = __autoMixedPrecisionOnednnBfloat16,
        autoMixedPrecisionCpu = __autoMixedPrecisionCpu,
        disableMetaOptimizer = __disableMetaOptimizer,
        disableTfgOptimizer = __disableTfgOptimizer,
        usePluginOptimizers = __usePluginOptimizers,
        experimentalConditionalCodeMotion = __experimentalConditionalCodeMotion,
        metaOptimizerIterations = __metaOptimizerIterations,
        minGraphNodes = __minGraphNodes,
        experimentalDisableCompressedTensorOptimization = __experimentalDisableCompressedTensorOptimization,
        experimentalDisableFoldingQuantizationEmulation = __experimentalDisableFoldingQuantizationEmulation,
        memoryOptimization = __memoryOptimization,
        memoryOptimizerTargetNodeNameScope = __memoryOptimizerTargetNodeNameScope,
        metaOptimizerTimeoutMs = __metaOptimizerTimeoutMs,
        autoParallel = __autoParallel,
        failOnOptimizerErrors = __failOnOptimizerErrors,
        scopedAllocatorOpts = __scopedAllocatorOpts,
        optimizers = __optimizers.result(),
        customOptimizers = __customOptimizers.result(),
        interOptimizerVerifierConfig = __interOptimizerVerifierConfig,
        postOptimizationVerifierConfig = __postOptimizationVerifierConfig,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[RewriterConfig] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      RewriterConfig(
        cpuLayoutConversion = rewriter_config.RewriterConfig.CpuLayout.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(50).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.CpuLayout.NO_CONVERSION_ON_CPU.scalaValueDescriptor).number),
        layoutOptimizer = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        constantFolding = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        shapeOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(13).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        remapping = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(14).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        commonSubgraphElimination = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(24).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        arithmeticOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(7).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        dependencyOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(8).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        loopOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(9).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        functionOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(10).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        debugStripper = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(11).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        disableModelPruning = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        scopedAllocatorOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(15).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        pinToHostOptimization = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(18).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        implementationSelector = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(22).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        autoMixedPrecision = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(23).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        autoMixedPrecisionMkl = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(25).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        autoMixedPrecisionOnednnBfloat16 = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(31).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        autoMixedPrecisionCpu = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(29).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        disableMetaOptimizer = __fieldsMap.get(scalaDescriptor.findFieldByNumber(19).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        disableTfgOptimizer = __fieldsMap.get(scalaDescriptor.findFieldByNumber(32).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        usePluginOptimizers = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(28).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        experimentalConditionalCodeMotion = rewriter_config.RewriterConfig.Toggle.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(30).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.Toggle.DEFAULT.scalaValueDescriptor).number),
        metaOptimizerIterations = rewriter_config.RewriterConfig.NumIterationsType.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(12).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.NumIterationsType.DEFAULT_NUM_ITERS.scalaValueDescriptor).number),
        minGraphNodes = __fieldsMap.get(scalaDescriptor.findFieldByNumber(17).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        experimentalDisableCompressedTensorOptimization = __fieldsMap.get(scalaDescriptor.findFieldByNumber(26).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        experimentalDisableFoldingQuantizationEmulation = __fieldsMap.get(scalaDescriptor.findFieldByNumber(27).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        memoryOptimization = rewriter_config.RewriterConfig.MemOptType.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(rewriter_config.RewriterConfig.MemOptType.DEFAULT_MEM_OPT.scalaValueDescriptor).number),
        memoryOptimizerTargetNodeNameScope = __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        metaOptimizerTimeoutMs = __fieldsMap.get(scalaDescriptor.findFieldByNumber(20).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        autoParallel = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).flatMap(_.as[_root_.scala.Option[AutoParallelOptions]]),
        failOnOptimizerErrors = __fieldsMap.get(scalaDescriptor.findFieldByNumber(21).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        scopedAllocatorOpts = __fieldsMap.get(scalaDescriptor.findFieldByNumber(16).get).flatMap(_.as[_root_.scala.Option[ScopedAllocatorOptions]]),
        optimizers = __fieldsMap.get(scalaDescriptor.findFieldByNumber(100).get).map(_.as[_root_.scala.Seq[_root_.scala.Predef.String]]).getOrElse(_root_.scala.Seq.empty),
        customOptimizers = __fieldsMap.get(scalaDescriptor.findFieldByNumber(200).get).map(_.as[_root_.scala.Seq[RewriterConfig.CustomGraphOptimizer]]).getOrElse(_root_.scala.Seq.empty),
        interOptimizerVerifierConfig = __fieldsMap.get(scalaDescriptor.findFieldByNumber(300).get).flatMap(_.as[_root_.scala.Option[VerifierConfig]]),
        postOptimizationVerifierConfig = __fieldsMap.get(scalaDescriptor.findFieldByNumber(301).get).flatMap(_.as[_root_.scala.Option[VerifierConfig]])
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.rewriter_config.RewriterConfigProto.javaDescriptor.getMessageTypes().get(2)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.rewriter_config.RewriterConfigProto.scalaDescriptor.messages(2)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 5 => __out = rewriter_config.AutoParallelOptions
      case 16 => __out = rewriter_config.ScopedAllocatorOptions
      case 200 => __out = rewriter_config.RewriterConfig.CustomGraphOptimizer
      case 300 => __out = verifier_config.VerifierConfig
      case 301 => __out = verifier_config.VerifierConfig
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] =
    Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]](
      rewriter_config.RewriterConfig.CustomGraphOptimizer
    )
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = {
    (__fieldNumber: @_root_.scala.unchecked) match {
      case 50 => rewriter_config.RewriterConfig.CpuLayout
      case 1 => rewriter_config.RewriterConfig.Toggle
      case 3 => rewriter_config.RewriterConfig.Toggle
      case 13 => rewriter_config.RewriterConfig.Toggle
      case 14 => rewriter_config.RewriterConfig.Toggle
      case 24 => rewriter_config.RewriterConfig.Toggle
      case 7 => rewriter_config.RewriterConfig.Toggle
      case 8 => rewriter_config.RewriterConfig.Toggle
      case 9 => rewriter_config.RewriterConfig.Toggle
      case 10 => rewriter_config.RewriterConfig.Toggle
      case 11 => rewriter_config.RewriterConfig.Toggle
      case 15 => rewriter_config.RewriterConfig.Toggle
      case 18 => rewriter_config.RewriterConfig.Toggle
      case 22 => rewriter_config.RewriterConfig.Toggle
      case 23 => rewriter_config.RewriterConfig.Toggle
      case 25 => rewriter_config.RewriterConfig.Toggle
      case 31 => rewriter_config.RewriterConfig.Toggle
      case 29 => rewriter_config.RewriterConfig.Toggle
      case 28 => rewriter_config.RewriterConfig.Toggle
      case 30 => rewriter_config.RewriterConfig.Toggle
      case 12 => rewriter_config.RewriterConfig.NumIterationsType
      case 4 => rewriter_config.RewriterConfig.MemOptType
    }
  }
  lazy val defaultInstance = RewriterConfig(
    cpuLayoutConversion = rewriter_config.RewriterConfig.CpuLayout.NO_CONVERSION_ON_CPU,
    layoutOptimizer = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    constantFolding = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    shapeOptimization = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    remapping = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    commonSubgraphElimination = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    arithmeticOptimization = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    dependencyOptimization = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    loopOptimization = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    functionOptimization = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    debugStripper = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    disableModelPruning = false,
    scopedAllocatorOptimization = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    pinToHostOptimization = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    implementationSelector = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    autoMixedPrecision = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    autoMixedPrecisionMkl = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    autoMixedPrecisionOnednnBfloat16 = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    autoMixedPrecisionCpu = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    disableMetaOptimizer = false,
    disableTfgOptimizer = false,
    usePluginOptimizers = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    experimentalConditionalCodeMotion = rewriter_config.RewriterConfig.Toggle.DEFAULT,
    metaOptimizerIterations = rewriter_config.RewriterConfig.NumIterationsType.DEFAULT_NUM_ITERS,
    minGraphNodes = 0,
    experimentalDisableCompressedTensorOptimization = false,
    experimentalDisableFoldingQuantizationEmulation = false,
    memoryOptimization = rewriter_config.RewriterConfig.MemOptType.DEFAULT_MEM_OPT,
    memoryOptimizerTargetNodeNameScope = "",
    metaOptimizerTimeoutMs = 0L,
    autoParallel = _root_.scala.None,
    failOnOptimizerErrors = false,
    scopedAllocatorOpts = _root_.scala.None,
    optimizers = _root_.scala.Seq.empty,
    customOptimizers = _root_.scala.Seq.empty,
    interOptimizerVerifierConfig = _root_.scala.None,
    postOptimizationVerifierConfig = _root_.scala.None
  )
  sealed abstract class Toggle(val value: _root_.scala.Int) extends _root_.scalapb.GeneratedEnum {
    type EnumType = RewriterConfig.Toggle
    type RecognizedType = RewriterConfig.Toggle.Recognized
    def isDefault: _root_.scala.Boolean = false
    def isOn: _root_.scala.Boolean = false
    def isOff: _root_.scala.Boolean = false
    def isAggressive: _root_.scala.Boolean = false
    def isExperimentalMlir: _root_.scala.Boolean = false
    def isExperimentalBoth: _root_.scala.Boolean = false
    def companion: _root_.scalapb.GeneratedEnumCompanion[Toggle] = rewriter_config.RewriterConfig.Toggle
    final def asRecognized: _root_.scala.Option[RewriterConfig.Toggle.Recognized] = if (isUnrecognized) _root_.scala.None else _root_.scala.Some(this.asInstanceOf[RewriterConfig.Toggle.Recognized])
  }
  
  object Toggle extends _root_.scalapb.GeneratedEnumCompanion[Toggle] {
    sealed trait Recognized extends Toggle
    implicit def enumCompanion: _root_.scalapb.GeneratedEnumCompanion[Toggle] = this
    
    @SerialVersionUID(0L)
    case object DEFAULT extends Toggle(0) with Toggle.Recognized {
      val index = 0
      val name = "DEFAULT"
      override def isDefault: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    case object ON extends Toggle(1) with Toggle.Recognized {
      val index = 1
      val name = "ON"
      override def isOn: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    case object OFF extends Toggle(2) with Toggle.Recognized {
      val index = 2
      val name = "OFF"
      override def isOff: _root_.scala.Boolean = true
    }
    
    /** Enable some aggressive optimizations that use assumptions that TF graphs
      * may break. For example, assume the shape of a placeholder matches its
      * actual feed.
      */
    @SerialVersionUID(0L)
    case object AGGRESSIVE extends Toggle(3) with Toggle.Recognized {
      val index = 3
      val name = "AGGRESSIVE"
      override def isAggressive: _root_.scala.Boolean = true
    }
    
    /** Run MLIR pass if there's one implemented in TFG, do nothing otherwise.
      * I.e., if there's no corresponding TFG pass, it's an OFF. This is supposed
      * to be mapped with `ON` and there's no `AGGRESSIVE` in MLIR pass now.
      */
    @SerialVersionUID(0L)
    case object EXPERIMENTAL_MLIR extends Toggle(4) with Toggle.Recognized {
      val index = 4
      val name = "EXPERIMENTAL_MLIR"
      override def isExperimentalMlir: _root_.scala.Boolean = true
    }
    
    /** Run both MLIR and Grappler passes consecutively and MLIR pass will come
      * first.
      */
    @SerialVersionUID(0L)
    case object EXPERIMENTAL_BOTH extends Toggle(5) with Toggle.Recognized {
      val index = 5
      val name = "EXPERIMENTAL_BOTH"
      override def isExperimentalBoth: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    final case class Unrecognized(unrecognizedValue: _root_.scala.Int) extends Toggle(unrecognizedValue) with _root_.scalapb.UnrecognizedEnum
    lazy val values: scala.collection.immutable.Seq[ValueType] = scala.collection.immutable.Seq(DEFAULT, ON, OFF, AGGRESSIVE, EXPERIMENTAL_MLIR, EXPERIMENTAL_BOTH)
    def fromValue(__value: _root_.scala.Int): Toggle = __value match {
      case 0 => DEFAULT
      case 1 => ON
      case 2 => OFF
      case 3 => AGGRESSIVE
      case 4 => EXPERIMENTAL_MLIR
      case 5 => EXPERIMENTAL_BOTH
      case __other => Unrecognized(__other)
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.EnumDescriptor = rewriter_config.RewriterConfig.javaDescriptor.getEnumTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.EnumDescriptor = rewriter_config.RewriterConfig.scalaDescriptor.enums(0)
  }
  /** Enum for layout conversion between NCHW and NHWC on CPU. Default is OFF.
    */
  sealed abstract class CpuLayout(val value: _root_.scala.Int) extends _root_.scalapb.GeneratedEnum {
    type EnumType = RewriterConfig.CpuLayout
    type RecognizedType = RewriterConfig.CpuLayout.Recognized
    def isNoConversionOnCpu: _root_.scala.Boolean = false
    def isNchwToNhwc: _root_.scala.Boolean = false
    def isNhwcToNchw: _root_.scala.Boolean = false
    def companion: _root_.scalapb.GeneratedEnumCompanion[CpuLayout] = rewriter_config.RewriterConfig.CpuLayout
    final def asRecognized: _root_.scala.Option[RewriterConfig.CpuLayout.Recognized] = if (isUnrecognized) _root_.scala.None else _root_.scala.Some(this.asInstanceOf[RewriterConfig.CpuLayout.Recognized])
  }
  
  object CpuLayout extends _root_.scalapb.GeneratedEnumCompanion[CpuLayout] {
    sealed trait Recognized extends CpuLayout
    implicit def enumCompanion: _root_.scalapb.GeneratedEnumCompanion[CpuLayout] = this
    
    @SerialVersionUID(0L)
    case object NO_CONVERSION_ON_CPU extends CpuLayout(0) with CpuLayout.Recognized {
      val index = 0
      val name = "NO_CONVERSION_ON_CPU"
      override def isNoConversionOnCpu: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    case object NCHW_TO_NHWC extends CpuLayout(1) with CpuLayout.Recognized {
      val index = 1
      val name = "NCHW_TO_NHWC"
      override def isNchwToNhwc: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    case object NHWC_TO_NCHW extends CpuLayout(2) with CpuLayout.Recognized {
      val index = 2
      val name = "NHWC_TO_NCHW"
      override def isNhwcToNchw: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    final case class Unrecognized(unrecognizedValue: _root_.scala.Int) extends CpuLayout(unrecognizedValue) with _root_.scalapb.UnrecognizedEnum
    lazy val values: scala.collection.immutable.Seq[ValueType] = scala.collection.immutable.Seq(NO_CONVERSION_ON_CPU, NCHW_TO_NHWC, NHWC_TO_NCHW)
    def fromValue(__value: _root_.scala.Int): CpuLayout = __value match {
      case 0 => NO_CONVERSION_ON_CPU
      case 1 => NCHW_TO_NHWC
      case 2 => NHWC_TO_NCHW
      case __other => Unrecognized(__other)
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.EnumDescriptor = rewriter_config.RewriterConfig.javaDescriptor.getEnumTypes().get(1)
    def scalaDescriptor: _root_.scalapb.descriptors.EnumDescriptor = rewriter_config.RewriterConfig.scalaDescriptor.enums(1)
  }
  /** Enum controlling the number of times to run optimizers. The default is to
    * run them twice.
    */
  sealed abstract class NumIterationsType(val value: _root_.scala.Int) extends _root_.scalapb.GeneratedEnum {
    type EnumType = RewriterConfig.NumIterationsType
    type RecognizedType = RewriterConfig.NumIterationsType.Recognized
    def isDefaultNumIters: _root_.scala.Boolean = false
    def isOne: _root_.scala.Boolean = false
    def isTwo: _root_.scala.Boolean = false
    def companion: _root_.scalapb.GeneratedEnumCompanion[NumIterationsType] = rewriter_config.RewriterConfig.NumIterationsType
    final def asRecognized: _root_.scala.Option[RewriterConfig.NumIterationsType.Recognized] = if (isUnrecognized) _root_.scala.None else _root_.scala.Some(this.asInstanceOf[RewriterConfig.NumIterationsType.Recognized])
  }
  
  object NumIterationsType extends _root_.scalapb.GeneratedEnumCompanion[NumIterationsType] {
    sealed trait Recognized extends NumIterationsType
    implicit def enumCompanion: _root_.scalapb.GeneratedEnumCompanion[NumIterationsType] = this
    
    @SerialVersionUID(0L)
    case object DEFAULT_NUM_ITERS extends NumIterationsType(0) with NumIterationsType.Recognized {
      val index = 0
      val name = "DEFAULT_NUM_ITERS"
      override def isDefaultNumIters: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    case object ONE extends NumIterationsType(1) with NumIterationsType.Recognized {
      val index = 1
      val name = "ONE"
      override def isOne: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    case object TWO extends NumIterationsType(2) with NumIterationsType.Recognized {
      val index = 2
      val name = "TWO"
      override def isTwo: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    final case class Unrecognized(unrecognizedValue: _root_.scala.Int) extends NumIterationsType(unrecognizedValue) with _root_.scalapb.UnrecognizedEnum
    lazy val values: scala.collection.immutable.Seq[ValueType] = scala.collection.immutable.Seq(DEFAULT_NUM_ITERS, ONE, TWO)
    def fromValue(__value: _root_.scala.Int): NumIterationsType = __value match {
      case 0 => DEFAULT_NUM_ITERS
      case 1 => ONE
      case 2 => TWO
      case __other => Unrecognized(__other)
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.EnumDescriptor = rewriter_config.RewriterConfig.javaDescriptor.getEnumTypes().get(2)
    def scalaDescriptor: _root_.scalapb.descriptors.EnumDescriptor = rewriter_config.RewriterConfig.scalaDescriptor.enums(2)
  }
  sealed abstract class MemOptType(val value: _root_.scala.Int) extends _root_.scalapb.GeneratedEnum {
    type EnumType = RewriterConfig.MemOptType
    type RecognizedType = RewriterConfig.MemOptType.Recognized
    def isDefaultMemOpt: _root_.scala.Boolean = false
    def isNoMemOpt: _root_.scala.Boolean = false
    def isManual: _root_.scala.Boolean = false
    def isSwappingHeuristics: _root_.scala.Boolean = false
    def isRecomputationHeuristics: _root_.scala.Boolean = false
    def isSchedulingHeuristics: _root_.scala.Boolean = false
    def isHeuristics: _root_.scala.Boolean = false
    def companion: _root_.scalapb.GeneratedEnumCompanion[MemOptType] = rewriter_config.RewriterConfig.MemOptType
    final def asRecognized: _root_.scala.Option[RewriterConfig.MemOptType.Recognized] = if (isUnrecognized) _root_.scala.None else _root_.scala.Some(this.asInstanceOf[RewriterConfig.MemOptType.Recognized])
  }
  
  object MemOptType extends _root_.scalapb.GeneratedEnumCompanion[MemOptType] {
    sealed trait Recognized extends MemOptType
    implicit def enumCompanion: _root_.scalapb.GeneratedEnumCompanion[MemOptType] = this
    
    /** The default setting (SCHEDULING and SWAPPING HEURISTICS only)
      */
    @SerialVersionUID(0L)
    case object DEFAULT_MEM_OPT extends MemOptType(0) with MemOptType.Recognized {
      val index = 0
      val name = "DEFAULT_MEM_OPT"
      override def isDefaultMemOpt: _root_.scala.Boolean = true
    }
    
    /** Disabled in the meta-optimizer.
      */
    @SerialVersionUID(0L)
    case object NO_MEM_OPT extends MemOptType(1) with MemOptType.Recognized {
      val index = 1
      val name = "NO_MEM_OPT"
      override def isNoMemOpt: _root_.scala.Boolean = true
    }
    
    /** Driven by manual op-level annotations.
      */
    @SerialVersionUID(0L)
    case object MANUAL extends MemOptType(2) with MemOptType.Recognized {
      val index = 2
      val name = "MANUAL"
      override def isManual: _root_.scala.Boolean = true
    }
    
    /** Swapping heuristic will move a tensor from the GPU to the CPU and move
      * it back when needed to reduce peak memory usage.
      */
    @SerialVersionUID(0L)
    case object SWAPPING_HEURISTICS extends MemOptType(4) with MemOptType.Recognized {
      val index = 3
      val name = "SWAPPING_HEURISTICS"
      override def isSwappingHeuristics: _root_.scala.Boolean = true
    }
    
    /** Recomputation heuristics will recompute ops (such as Relu activation)
      * during backprop instead of storing them, reducing peak memory usage.
      */
    @SerialVersionUID(0L)
    case object RECOMPUTATION_HEURISTICS extends MemOptType(5) with MemOptType.Recognized {
      val index = 4
      val name = "RECOMPUTATION_HEURISTICS"
      override def isRecomputationHeuristics: _root_.scala.Boolean = true
    }
    
    /** Scheduling will split big ops such as AddN and try to enforce a schedule
      * of the new computations that decreases peak memory usage.
      */
    @SerialVersionUID(0L)
    case object SCHEDULING_HEURISTICS extends MemOptType(6) with MemOptType.Recognized {
      val index = 5
      val name = "SCHEDULING_HEURISTICS"
      override def isSchedulingHeuristics: _root_.scala.Boolean = true
    }
    
    /** Use any combination of swapping and recomputation heuristics.
      */
    @SerialVersionUID(0L)
    case object HEURISTICS extends MemOptType(3) with MemOptType.Recognized {
      val index = 6
      val name = "HEURISTICS"
      override def isHeuristics: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    final case class Unrecognized(unrecognizedValue: _root_.scala.Int) extends MemOptType(unrecognizedValue) with _root_.scalapb.UnrecognizedEnum
    lazy val values: scala.collection.immutable.Seq[ValueType] = scala.collection.immutable.Seq(DEFAULT_MEM_OPT, NO_MEM_OPT, MANUAL, SWAPPING_HEURISTICS, RECOMPUTATION_HEURISTICS, SCHEDULING_HEURISTICS, HEURISTICS)
    def fromValue(__value: _root_.scala.Int): MemOptType = __value match {
      case 0 => DEFAULT_MEM_OPT
      case 1 => NO_MEM_OPT
      case 2 => MANUAL
      case 3 => HEURISTICS
      case 4 => SWAPPING_HEURISTICS
      case 5 => RECOMPUTATION_HEURISTICS
      case 6 => SCHEDULING_HEURISTICS
      case __other => Unrecognized(__other)
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.EnumDescriptor = rewriter_config.RewriterConfig.javaDescriptor.getEnumTypes().get(3)
    def scalaDescriptor: _root_.scalapb.descriptors.EnumDescriptor = rewriter_config.RewriterConfig.scalaDescriptor.enums(3)
  }
  /** Message to describe custom graph optimizer and its parameters
    */
  @SerialVersionUID(0L)
  final case class CustomGraphOptimizer(
                                         name: _root_.scala.Predef.String = "",
                                         parameterMap: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, AttrValue] = _root_.scala.collection.immutable.Map.empty,
                                         unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[CustomGraphOptimizer] {
      @transient
      private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
      private[this] def __computeSerializedSize(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = name
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
          }
        };
        parameterMap.foreach { __item =>
          val __value = rewriter_config.RewriterConfig.CustomGraphOptimizer._typemapper_parameterMap.toBase(__item)
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        }
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var __size = __serializedSizeMemoized
        if (__size == 0) {
          __size = __computeSerializedSize() + 1
          __serializedSizeMemoized = __size
        }
        __size - 1
        
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = name
          if (!__v.isEmpty) {
            _output__.writeString(1, __v)
          }
        };
        parameterMap.foreach { __v =>
          val __m = rewriter_config.RewriterConfig.CustomGraphOptimizer._typemapper_parameterMap.toBase(__v)
          _output__.writeTag(2, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        unknownFields.writeTo(_output__)
      }
      def withName(__v: _root_.scala.Predef.String): CustomGraphOptimizer = copy(name = __v)
      def clearParameterMap = copy(parameterMap = _root_.scala.collection.immutable.Map.empty)
      def addParameterMap(__vs: (_root_.scala.Predef.String, AttrValue) *): CustomGraphOptimizer = addAllParameterMap(__vs)
      def addAllParameterMap(__vs: Iterable[(_root_.scala.Predef.String, AttrValue)]): CustomGraphOptimizer = copy(parameterMap = parameterMap ++ __vs)
      def withParameterMap(__v: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, AttrValue]): CustomGraphOptimizer = copy(parameterMap = __v)
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = name
            if (__t != "") __t else null
          }
          case 2 => parameterMap.iterator.map(rewriter_config.RewriterConfig.CustomGraphOptimizer._typemapper_parameterMap.toBase(_)).toSeq
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PString(name)
          case 2 => _root_.scalapb.descriptors.PRepeated(parameterMap.iterator.map(rewriter_config.RewriterConfig.CustomGraphOptimizer._typemapper_parameterMap.toBase(_).toPMessage).toVector)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion: RewriterConfig.CustomGraphOptimizer.type = rewriter_config.RewriterConfig.CustomGraphOptimizer
      // @@protoc_insertion_point(GeneratedMessage[tensorboard.RewriterConfig.CustomGraphOptimizer])
  }
  
  object CustomGraphOptimizer extends scalapb.GeneratedMessageCompanion[RewriterConfig.CustomGraphOptimizer] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[RewriterConfig.CustomGraphOptimizer] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): RewriterConfig.CustomGraphOptimizer = {
      var __name: _root_.scala.Predef.String = ""
      val __parameterMap: _root_.scala.collection.mutable.Builder[(_root_.scala.Predef.String, AttrValue), _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, AttrValue]] = _root_.scala.collection.immutable.Map.newBuilder[_root_.scala.Predef.String, AttrValue]
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 10 =>
            __name = _input__.readStringRequireUtf8()
          case 18 =>
            __parameterMap += rewriter_config.RewriterConfig.CustomGraphOptimizer._typemapper_parameterMap.toCustom(_root_.scalapb.LiteParser.readMessage[RewriterConfig.CustomGraphOptimizer.ParameterMapEntry](_input__))
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      rewriter_config.RewriterConfig.CustomGraphOptimizer(
          name = __name,
          parameterMap = __parameterMap.result(),
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[RewriterConfig.CustomGraphOptimizer] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        rewriter_config.RewriterConfig.CustomGraphOptimizer(
          name = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
          parameterMap = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[RewriterConfig.CustomGraphOptimizer.ParameterMapEntry]]).getOrElse(_root_.scala.Seq.empty).iterator.map(rewriter_config.RewriterConfig.CustomGraphOptimizer._typemapper_parameterMap.toCustom(_)).toMap
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = rewriter_config.RewriterConfig.javaDescriptor.getNestedTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = rewriter_config.RewriterConfig.scalaDescriptor.nestedMessages(0)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
      var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
      (__number: @_root_.scala.unchecked) match {
        case 2 => __out = rewriter_config.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry
      }
      __out
    }
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] =
      Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]](
        rewriter_config.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry
      )
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = rewriter_config.RewriterConfig.CustomGraphOptimizer(
      name = "",
      parameterMap = _root_.scala.collection.immutable.Map.empty
    )
    @SerialVersionUID(0L)
    final case class ParameterMapEntry(
                                        key: _root_.scala.Predef.String = "",
                                        value: _root_.scala.Option[AttrValue] = _root_.scala.None,
                                        unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
        ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[ParameterMapEntry] {
        @transient
        private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
        private[this] def __computeSerializedSize(): _root_.scala.Int = {
          var __size = 0
          
          {
            val __value = key
            if (!__value.isEmpty) {
              __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
            }
          };
          if (value.isDefined) {
            val __value = value.get
            __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
          };
          __size += unknownFields.serializedSize
          __size
        }
        override def serializedSize: _root_.scala.Int = {
          var __size = __serializedSizeMemoized
          if (__size == 0) {
            __size = __computeSerializedSize() + 1
            __serializedSizeMemoized = __size
          }
          __size - 1
          
        }
        def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
          {
            val __v = key
            if (!__v.isEmpty) {
              _output__.writeString(1, __v)
            }
          };
          value.foreach { __v =>
            val __m = __v
            _output__.writeTag(2, 2)
            _output__.writeUInt32NoTag(__m.serializedSize)
            __m.writeTo(_output__)
          };
          unknownFields.writeTo(_output__)
        }
        def withKey(__v: _root_.scala.Predef.String): ParameterMapEntry = copy(key = __v)
        def getValue: AttrValue = value.getOrElse(attr_value.AttrValue.defaultInstance)
        def clearValue: ParameterMapEntry = copy(value = _root_.scala.None)
        def withValue(__v: AttrValue): ParameterMapEntry = copy(value = Option(__v))
        def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
        def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
        def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
          (__fieldNumber: @_root_.scala.unchecked) match {
            case 1 => {
              val __t = key
              if (__t != "") __t else null
            }
            case 2 => value.orNull
          }
        }
        def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
          _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
          (__field.number: @_root_.scala.unchecked) match {
            case 1 => _root_.scalapb.descriptors.PString(key)
            case 2 => value.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
          }
        }
        def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
        def companion: RewriterConfig.CustomGraphOptimizer.ParameterMapEntry.type = rewriter_config.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry
        // @@protoc_insertion_point(GeneratedMessage[tensorboard.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry])
    }
    
    object ParameterMapEntry extends scalapb.GeneratedMessageCompanion[RewriterConfig.CustomGraphOptimizer.ParameterMapEntry] {
      implicit def messageCompanion: scalapb.GeneratedMessageCompanion[RewriterConfig.CustomGraphOptimizer.ParameterMapEntry] = this
      def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): RewriterConfig.CustomGraphOptimizer.ParameterMapEntry = {
        var __key: _root_.scala.Predef.String = ""
        var __value: _root_.scala.Option[AttrValue] = _root_.scala.None
        var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
        var _done__ = false
        while (!_done__) {
          val _tag__ = _input__.readTag()
          _tag__ match {
            case 0 => _done__ = true
            case 10 =>
              __key = _input__.readStringRequireUtf8()
            case 18 =>
              __value = _root_.scala.Option(__value.fold(_root_.scalapb.LiteParser.readMessage[AttrValue](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
            case tag =>
              if (_unknownFields__ == null) {
                _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
              }
              _unknownFields__.parseField(tag, _input__)
          }
        }
        rewriter_config.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry(
            key = __key,
            value = __value,
            unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
        )
      }
      implicit def messageReads: _root_.scalapb.descriptors.Reads[RewriterConfig.CustomGraphOptimizer.ParameterMapEntry] = _root_.scalapb.descriptors.Reads{
        case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
          _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
          rewriter_config.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry(
            key = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
            value = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[AttrValue]])
          )
        case _ => throw new RuntimeException("Expected PMessage")
      }
      def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = rewriter_config.RewriterConfig.CustomGraphOptimizer.javaDescriptor.getNestedTypes().get(0)
      def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = rewriter_config.RewriterConfig.CustomGraphOptimizer.scalaDescriptor.nestedMessages(0)
      def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
        var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
        (__number: @_root_.scala.unchecked) match {
          case 2 => __out = attr_value.AttrValue
        }
        __out
      }
      lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
      def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
      lazy val defaultInstance = rewriter_config.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry(
        key = "",
        value = _root_.scala.None
      )
      implicit class ParameterMapEntryLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.CustomGraphOptimizer.ParameterMapEntry]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, RewriterConfig.CustomGraphOptimizer.ParameterMapEntry](_l) {
        def key: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.key)((c_, f_) => c_.copy(key = f_))
        def value: _root_.scalapb.lenses.Lens[UpperPB, AttrValue] = field(_.getValue)((c_, f_) => c_.copy(value = _root_.scala.Option(f_)))
        def optionalValue: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[AttrValue]] = field(_.value)((c_, f_) => c_.copy(value = f_))
      }
      final val KEY_FIELD_NUMBER = 1
      final val VALUE_FIELD_NUMBER = 2
      @transient
      implicit val keyValueMapper: _root_.scalapb.TypeMapper[RewriterConfig.CustomGraphOptimizer.ParameterMapEntry, (_root_.scala.Predef.String, AttrValue)] =
        _root_.scalapb.TypeMapper[RewriterConfig.CustomGraphOptimizer.ParameterMapEntry, (_root_.scala.Predef.String, AttrValue)](__m => (__m.key, __m.getValue))(__p => rewriter_config.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry(__p._1, Some(__p._2)))
      def of(
        key: _root_.scala.Predef.String,
        value: _root_.scala.Option[AttrValue]
      ): RewriterConfig.CustomGraphOptimizer.ParameterMapEntry = rewriter_config.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry(
        key,
        value
      )
      // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry])
    }
    
    implicit class CustomGraphOptimizerLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.CustomGraphOptimizer]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, RewriterConfig.CustomGraphOptimizer](_l) {
      def name: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.name)((c_, f_) => c_.copy(name = f_))
      def parameterMap: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, AttrValue]] = field(_.parameterMap)((c_, f_) => c_.copy(parameterMap = f_))
    }
    final val NAME_FIELD_NUMBER = 1
    final val PARAMETER_MAP_FIELD_NUMBER = 2
    @transient
    private[rewriter_config] val _typemapper_parameterMap: _root_.scalapb.TypeMapper[RewriterConfig.CustomGraphOptimizer.ParameterMapEntry, (_root_.scala.Predef.String, AttrValue)] = implicitly[_root_.scalapb.TypeMapper[RewriterConfig.CustomGraphOptimizer.ParameterMapEntry, (_root_.scala.Predef.String, AttrValue)]]
    def of(
      name: _root_.scala.Predef.String,
      parameterMap: _root_.scala.collection.immutable.Map[_root_.scala.Predef.String, AttrValue]
    ): RewriterConfig.CustomGraphOptimizer = rewriter_config.RewriterConfig.CustomGraphOptimizer(
      name,
      parameterMap
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.RewriterConfig.CustomGraphOptimizer])
  }
  
  implicit class RewriterConfigLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, RewriterConfig](_l) {
    def cpuLayoutConversion: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.CpuLayout] = field(_.cpuLayoutConversion)((c_, f_) => c_.copy(cpuLayoutConversion = f_))
    def layoutOptimizer: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.layoutOptimizer)((c_, f_) => c_.copy(layoutOptimizer = f_))
    def constantFolding: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.constantFolding)((c_, f_) => c_.copy(constantFolding = f_))
    def shapeOptimization: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.shapeOptimization)((c_, f_) => c_.copy(shapeOptimization = f_))
    def remapping: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.remapping)((c_, f_) => c_.copy(remapping = f_))
    def commonSubgraphElimination: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.commonSubgraphElimination)((c_, f_) => c_.copy(commonSubgraphElimination = f_))
    def arithmeticOptimization: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.arithmeticOptimization)((c_, f_) => c_.copy(arithmeticOptimization = f_))
    def dependencyOptimization: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.dependencyOptimization)((c_, f_) => c_.copy(dependencyOptimization = f_))
    def loopOptimization: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.loopOptimization)((c_, f_) => c_.copy(loopOptimization = f_))
    def functionOptimization: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.functionOptimization)((c_, f_) => c_.copy(functionOptimization = f_))
    def debugStripper: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.debugStripper)((c_, f_) => c_.copy(debugStripper = f_))
    def disableModelPruning: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.disableModelPruning)((c_, f_) => c_.copy(disableModelPruning = f_))
    def scopedAllocatorOptimization: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.scopedAllocatorOptimization)((c_, f_) => c_.copy(scopedAllocatorOptimization = f_))
    def pinToHostOptimization: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.pinToHostOptimization)((c_, f_) => c_.copy(pinToHostOptimization = f_))
    def implementationSelector: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.implementationSelector)((c_, f_) => c_.copy(implementationSelector = f_))
    def autoMixedPrecision: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.autoMixedPrecision)((c_, f_) => c_.copy(autoMixedPrecision = f_))
    def autoMixedPrecisionMkl: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.autoMixedPrecisionMkl)((c_, f_) => c_.copy(autoMixedPrecisionMkl = f_))
    def autoMixedPrecisionOnednnBfloat16: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.autoMixedPrecisionOnednnBfloat16)((c_, f_) => c_.copy(autoMixedPrecisionOnednnBfloat16 = f_))
    def autoMixedPrecisionCpu: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.autoMixedPrecisionCpu)((c_, f_) => c_.copy(autoMixedPrecisionCpu = f_))
    def disableMetaOptimizer: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.disableMetaOptimizer)((c_, f_) => c_.copy(disableMetaOptimizer = f_))
    def disableTfgOptimizer: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.disableTfgOptimizer)((c_, f_) => c_.copy(disableTfgOptimizer = f_))
    def usePluginOptimizers: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.usePluginOptimizers)((c_, f_) => c_.copy(usePluginOptimizers = f_))
    def experimentalConditionalCodeMotion: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.Toggle] = field(_.experimentalConditionalCodeMotion)((c_, f_) => c_.copy(experimentalConditionalCodeMotion = f_))
    def metaOptimizerIterations: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.NumIterationsType] = field(_.metaOptimizerIterations)((c_, f_) => c_.copy(metaOptimizerIterations = f_))
    def minGraphNodes: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.minGraphNodes)((c_, f_) => c_.copy(minGraphNodes = f_))
    def experimentalDisableCompressedTensorOptimization: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.experimentalDisableCompressedTensorOptimization)((c_, f_) => c_.copy(experimentalDisableCompressedTensorOptimization = f_))
    def experimentalDisableFoldingQuantizationEmulation: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.experimentalDisableFoldingQuantizationEmulation)((c_, f_) => c_.copy(experimentalDisableFoldingQuantizationEmulation = f_))
    def memoryOptimization: _root_.scalapb.lenses.Lens[UpperPB, RewriterConfig.MemOptType] = field(_.memoryOptimization)((c_, f_) => c_.copy(memoryOptimization = f_))
    def memoryOptimizerTargetNodeNameScope: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.memoryOptimizerTargetNodeNameScope)((c_, f_) => c_.copy(memoryOptimizerTargetNodeNameScope = f_))
    def metaOptimizerTimeoutMs: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.metaOptimizerTimeoutMs)((c_, f_) => c_.copy(metaOptimizerTimeoutMs = f_))
    def autoParallel: _root_.scalapb.lenses.Lens[UpperPB, AutoParallelOptions] = field(_.getAutoParallel)((c_, f_) => c_.copy(autoParallel = _root_.scala.Option(f_)))
    def optionalAutoParallel: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[AutoParallelOptions]] = field(_.autoParallel)((c_, f_) => c_.copy(autoParallel = f_))
    def failOnOptimizerErrors: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.failOnOptimizerErrors)((c_, f_) => c_.copy(failOnOptimizerErrors = f_))
    def scopedAllocatorOpts: _root_.scalapb.lenses.Lens[UpperPB, ScopedAllocatorOptions] = field(_.getScopedAllocatorOpts)((c_, f_) => c_.copy(scopedAllocatorOpts = _root_.scala.Option(f_)))
    def optionalScopedAllocatorOpts: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[ScopedAllocatorOptions]] = field(_.scopedAllocatorOpts)((c_, f_) => c_.copy(scopedAllocatorOpts = f_))
    def optimizers: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Predef.String]] = field(_.optimizers)((c_, f_) => c_.copy(optimizers = f_))
    def customOptimizers: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[RewriterConfig.CustomGraphOptimizer]] = field(_.customOptimizers)((c_, f_) => c_.copy(customOptimizers = f_))
    def interOptimizerVerifierConfig: _root_.scalapb.lenses.Lens[UpperPB, VerifierConfig] = field(_.getInterOptimizerVerifierConfig)((c_, f_) => c_.copy(interOptimizerVerifierConfig = _root_.scala.Option(f_)))
    def optionalInterOptimizerVerifierConfig: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[VerifierConfig]] = field(_.interOptimizerVerifierConfig)((c_, f_) => c_.copy(interOptimizerVerifierConfig = f_))
    def postOptimizationVerifierConfig: _root_.scalapb.lenses.Lens[UpperPB, VerifierConfig] = field(_.getPostOptimizationVerifierConfig)((c_, f_) => c_.copy(postOptimizationVerifierConfig = _root_.scala.Option(f_)))
    def optionalPostOptimizationVerifierConfig: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[VerifierConfig]] = field(_.postOptimizationVerifierConfig)((c_, f_) => c_.copy(postOptimizationVerifierConfig = f_))
  }
  final val CPU_LAYOUT_CONVERSION_FIELD_NUMBER = 50
  final val LAYOUT_OPTIMIZER_FIELD_NUMBER = 1
  final val CONSTANT_FOLDING_FIELD_NUMBER = 3
  final val SHAPE_OPTIMIZATION_FIELD_NUMBER = 13
  final val REMAPPING_FIELD_NUMBER = 14
  final val COMMON_SUBGRAPH_ELIMINATION_FIELD_NUMBER = 24
  final val ARITHMETIC_OPTIMIZATION_FIELD_NUMBER = 7
  final val DEPENDENCY_OPTIMIZATION_FIELD_NUMBER = 8
  final val LOOP_OPTIMIZATION_FIELD_NUMBER = 9
  final val FUNCTION_OPTIMIZATION_FIELD_NUMBER = 10
  final val DEBUG_STRIPPER_FIELD_NUMBER = 11
  final val DISABLE_MODEL_PRUNING_FIELD_NUMBER = 2
  final val SCOPED_ALLOCATOR_OPTIMIZATION_FIELD_NUMBER = 15
  final val PIN_TO_HOST_OPTIMIZATION_FIELD_NUMBER = 18
  final val IMPLEMENTATION_SELECTOR_FIELD_NUMBER = 22
  final val AUTO_MIXED_PRECISION_FIELD_NUMBER = 23
  final val AUTO_MIXED_PRECISION_MKL_FIELD_NUMBER = 25
  final val AUTO_MIXED_PRECISION_ONEDNN_BFLOAT16_FIELD_NUMBER = 31
  final val AUTO_MIXED_PRECISION_CPU_FIELD_NUMBER = 29
  final val DISABLE_META_OPTIMIZER_FIELD_NUMBER = 19
  final val DISABLE_TFG_OPTIMIZER_FIELD_NUMBER = 32
  final val USE_PLUGIN_OPTIMIZERS_FIELD_NUMBER = 28
  final val EXPERIMENTAL_CONDITIONAL_CODE_MOTION_FIELD_NUMBER = 30
  final val META_OPTIMIZER_ITERATIONS_FIELD_NUMBER = 12
  final val MIN_GRAPH_NODES_FIELD_NUMBER = 17
  final val EXPERIMENTAL_DISABLE_COMPRESSED_TENSOR_OPTIMIZATION_FIELD_NUMBER = 26
  final val EXPERIMENTAL_DISABLE_FOLDING_QUANTIZATION_EMULATION_FIELD_NUMBER = 27
  final val MEMORY_OPTIMIZATION_FIELD_NUMBER = 4
  final val MEMORY_OPTIMIZER_TARGET_NODE_NAME_SCOPE_FIELD_NUMBER = 6
  final val META_OPTIMIZER_TIMEOUT_MS_FIELD_NUMBER = 20
  final val AUTO_PARALLEL_FIELD_NUMBER = 5
  final val FAIL_ON_OPTIMIZER_ERRORS_FIELD_NUMBER = 21
  final val SCOPED_ALLOCATOR_OPTS_FIELD_NUMBER = 16
  final val OPTIMIZERS_FIELD_NUMBER = 100
  final val CUSTOM_OPTIMIZERS_FIELD_NUMBER = 200
  final val INTER_OPTIMIZER_VERIFIER_CONFIG_FIELD_NUMBER = 300
  final val POST_OPTIMIZATION_VERIFIER_CONFIG_FIELD_NUMBER = 301
  def of(
          cpuLayoutConversion: RewriterConfig.CpuLayout,
          layoutOptimizer: RewriterConfig.Toggle,
          constantFolding: RewriterConfig.Toggle,
          shapeOptimization: RewriterConfig.Toggle,
          remapping: RewriterConfig.Toggle,
          commonSubgraphElimination: RewriterConfig.Toggle,
          arithmeticOptimization: RewriterConfig.Toggle,
          dependencyOptimization: RewriterConfig.Toggle,
          loopOptimization: RewriterConfig.Toggle,
          functionOptimization: RewriterConfig.Toggle,
          debugStripper: RewriterConfig.Toggle,
          disableModelPruning: _root_.scala.Boolean,
          scopedAllocatorOptimization: RewriterConfig.Toggle,
          pinToHostOptimization: RewriterConfig.Toggle,
          implementationSelector: RewriterConfig.Toggle,
          autoMixedPrecision: RewriterConfig.Toggle,
          autoMixedPrecisionMkl: RewriterConfig.Toggle,
          autoMixedPrecisionOnednnBfloat16: RewriterConfig.Toggle,
          autoMixedPrecisionCpu: RewriterConfig.Toggle,
          disableMetaOptimizer: _root_.scala.Boolean,
          disableTfgOptimizer: _root_.scala.Boolean,
          usePluginOptimizers: RewriterConfig.Toggle,
          experimentalConditionalCodeMotion: RewriterConfig.Toggle,
          metaOptimizerIterations: RewriterConfig.NumIterationsType,
          minGraphNodes: _root_.scala.Int,
          experimentalDisableCompressedTensorOptimization: _root_.scala.Boolean,
          experimentalDisableFoldingQuantizationEmulation: _root_.scala.Boolean,
          memoryOptimization: RewriterConfig.MemOptType,
          memoryOptimizerTargetNodeNameScope: _root_.scala.Predef.String,
          metaOptimizerTimeoutMs: _root_.scala.Long,
          autoParallel: _root_.scala.Option[AutoParallelOptions],
          failOnOptimizerErrors: _root_.scala.Boolean,
          scopedAllocatorOpts: _root_.scala.Option[ScopedAllocatorOptions],
          optimizers: _root_.scala.Seq[_root_.scala.Predef.String],
          customOptimizers: _root_.scala.Seq[RewriterConfig.CustomGraphOptimizer],
          interOptimizerVerifierConfig: _root_.scala.Option[VerifierConfig],
          postOptimizationVerifierConfig: _root_.scala.Option[VerifierConfig]
  ): RewriterConfig = RewriterConfig(
    cpuLayoutConversion,
    layoutOptimizer,
    constantFolding,
    shapeOptimization,
    remapping,
    commonSubgraphElimination,
    arithmeticOptimization,
    dependencyOptimization,
    loopOptimization,
    functionOptimization,
    debugStripper,
    disableModelPruning,
    scopedAllocatorOptimization,
    pinToHostOptimization,
    implementationSelector,
    autoMixedPrecision,
    autoMixedPrecisionMkl,
    autoMixedPrecisionOnednnBfloat16,
    autoMixedPrecisionCpu,
    disableMetaOptimizer,
    disableTfgOptimizer,
    usePluginOptimizers,
    experimentalConditionalCodeMotion,
    metaOptimizerIterations,
    minGraphNodes,
    experimentalDisableCompressedTensorOptimization,
    experimentalDisableFoldingQuantizationEmulation,
    memoryOptimization,
    memoryOptimizerTargetNodeNameScope,
    metaOptimizerTimeoutMs,
    autoParallel,
    failOnOptimizerErrors,
    scopedAllocatorOpts,
    optimizers,
    customOptimizers,
    interOptimizerVerifierConfig,
    postOptimizationVerifierConfig
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.RewriterConfig])
}
