// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package tensorflow.framework.step_stats

import tensorflow.framework.step_stats

/** @param totalBytes
  *   These are per-node allocator memory stats.
  * @param liveBytes
  *   The bytes that are not deallocated.
  * @param allocationRecords
  *   The allocation and deallocation timeline.
  * @param allocatorBytesInUse
  *   These are snapshots of the overall allocator memory stats.
  *   The number of live bytes currently allocated by the allocator.
  */
@SerialVersionUID(0L)
final case class AllocatorMemoryUsed(
                                      allocatorName: _root_.scala.Predef.String = "",
                                      totalBytes: _root_.scala.Long = 0L,
                                      peakBytes: _root_.scala.Long = 0L,
                                      liveBytes: _root_.scala.Long = 0L,
                                      allocationRecords: _root_.scala.Seq[AllocationRecord] = _root_.scala.Seq.empty,
                                      allocatorBytesInUse: _root_.scala.Long = 0L,
                                      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[AllocatorMemoryUsed] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = allocatorName
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
        }
      };
      
      {
        val __value = totalBytes
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(2, __value)
        }
      };
      
      {
        val __value = peakBytes
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(3, __value)
        }
      };
      
      {
        val __value = liveBytes
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(4, __value)
        }
      };
      allocationRecords.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      
      {
        val __value = allocatorBytesInUse
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(5, __value)
        }
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = allocatorName
        if (!__v.isEmpty) {
          _output__.writeString(1, __v)
        }
      };
      {
        val __v = totalBytes
        if (__v != 0L) {
          _output__.writeInt64(2, __v)
        }
      };
      {
        val __v = peakBytes
        if (__v != 0L) {
          _output__.writeInt64(3, __v)
        }
      };
      {
        val __v = liveBytes
        if (__v != 0L) {
          _output__.writeInt64(4, __v)
        }
      };
      {
        val __v = allocatorBytesInUse
        if (__v != 0L) {
          _output__.writeInt64(5, __v)
        }
      };
      allocationRecords.foreach { __v =>
        val __m = __v
        _output__.writeTag(6, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      unknownFields.writeTo(_output__)
    }
    def withAllocatorName(__v: _root_.scala.Predef.String): AllocatorMemoryUsed = copy(allocatorName = __v)
    def withTotalBytes(__v: _root_.scala.Long): AllocatorMemoryUsed = copy(totalBytes = __v)
    def withPeakBytes(__v: _root_.scala.Long): AllocatorMemoryUsed = copy(peakBytes = __v)
    def withLiveBytes(__v: _root_.scala.Long): AllocatorMemoryUsed = copy(liveBytes = __v)
    def clearAllocationRecords = copy(allocationRecords = _root_.scala.Seq.empty)
    def addAllocationRecords(__vs: AllocationRecord *): AllocatorMemoryUsed = addAllAllocationRecords(__vs)
    def addAllAllocationRecords(__vs: Iterable[AllocationRecord]): AllocatorMemoryUsed = copy(allocationRecords = allocationRecords ++ __vs)
    def withAllocationRecords(__v: _root_.scala.Seq[AllocationRecord]): AllocatorMemoryUsed = copy(allocationRecords = __v)
    def withAllocatorBytesInUse(__v: _root_.scala.Long): AllocatorMemoryUsed = copy(allocatorBytesInUse = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = allocatorName
          if (__t != "") __t else null
        }
        case 2 => {
          val __t = totalBytes
          if (__t != 0L) __t else null
        }
        case 3 => {
          val __t = peakBytes
          if (__t != 0L) __t else null
        }
        case 4 => {
          val __t = liveBytes
          if (__t != 0L) __t else null
        }
        case 6 => allocationRecords
        case 5 => {
          val __t = allocatorBytesInUse
          if (__t != 0L) __t else null
        }
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PString(allocatorName)
        case 2 => _root_.scalapb.descriptors.PLong(totalBytes)
        case 3 => _root_.scalapb.descriptors.PLong(peakBytes)
        case 4 => _root_.scalapb.descriptors.PLong(liveBytes)
        case 6 => _root_.scalapb.descriptors.PRepeated(allocationRecords.iterator.map(_.toPMessage).toVector)
        case 5 => _root_.scalapb.descriptors.PLong(allocatorBytesInUse)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: AllocatorMemoryUsed.type = step_stats.AllocatorMemoryUsed
    // @@protoc_insertion_point(GeneratedMessage[tensorboard.AllocatorMemoryUsed])
}

object AllocatorMemoryUsed extends scalapb.GeneratedMessageCompanion[AllocatorMemoryUsed] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[AllocatorMemoryUsed] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): AllocatorMemoryUsed = {
    var __allocatorName: _root_.scala.Predef.String = ""
    var __totalBytes: _root_.scala.Long = 0L
    var __peakBytes: _root_.scala.Long = 0L
    var __liveBytes: _root_.scala.Long = 0L
    val __allocationRecords: _root_.scala.collection.immutable.VectorBuilder[AllocationRecord] = new _root_.scala.collection.immutable.VectorBuilder[AllocationRecord]
    var __allocatorBytesInUse: _root_.scala.Long = 0L
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __allocatorName = _input__.readStringRequireUtf8()
        case 16 =>
          __totalBytes = _input__.readInt64()
        case 24 =>
          __peakBytes = _input__.readInt64()
        case 32 =>
          __liveBytes = _input__.readInt64()
        case 50 =>
          __allocationRecords += _root_.scalapb.LiteParser.readMessage[AllocationRecord](_input__)
        case 40 =>
          __allocatorBytesInUse = _input__.readInt64()
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    AllocatorMemoryUsed(
        allocatorName = __allocatorName,
        totalBytes = __totalBytes,
        peakBytes = __peakBytes,
        liveBytes = __liveBytes,
        allocationRecords = __allocationRecords.result(),
        allocatorBytesInUse = __allocatorBytesInUse,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[AllocatorMemoryUsed] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      AllocatorMemoryUsed(
        allocatorName = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        totalBytes = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        peakBytes = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        liveBytes = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        allocationRecords = __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).map(_.as[_root_.scala.Seq[AllocationRecord]]).getOrElse(_root_.scala.Seq.empty),
        allocatorBytesInUse = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Long]).getOrElse(0L)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.step_stats.StepStatsProto.javaDescriptor.getMessageTypes().get(1)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.step_stats.StepStatsProto.scalaDescriptor.messages(1)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 6 => __out = step_stats.AllocationRecord
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = AllocatorMemoryUsed(
    allocatorName = "",
    totalBytes = 0L,
    peakBytes = 0L,
    liveBytes = 0L,
    allocationRecords = _root_.scala.Seq.empty,
    allocatorBytesInUse = 0L
  )
  implicit class AllocatorMemoryUsedLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, AllocatorMemoryUsed]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, AllocatorMemoryUsed](_l) {
    def allocatorName: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.allocatorName)((c_, f_) => c_.copy(allocatorName = f_))
    def totalBytes: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.totalBytes)((c_, f_) => c_.copy(totalBytes = f_))
    def peakBytes: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.peakBytes)((c_, f_) => c_.copy(peakBytes = f_))
    def liveBytes: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.liveBytes)((c_, f_) => c_.copy(liveBytes = f_))
    def allocationRecords: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[AllocationRecord]] = field(_.allocationRecords)((c_, f_) => c_.copy(allocationRecords = f_))
    def allocatorBytesInUse: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.allocatorBytesInUse)((c_, f_) => c_.copy(allocatorBytesInUse = f_))
  }
  final val ALLOCATOR_NAME_FIELD_NUMBER = 1
  final val TOTAL_BYTES_FIELD_NUMBER = 2
  final val PEAK_BYTES_FIELD_NUMBER = 3
  final val LIVE_BYTES_FIELD_NUMBER = 4
  final val ALLOCATION_RECORDS_FIELD_NUMBER = 6
  final val ALLOCATOR_BYTES_IN_USE_FIELD_NUMBER = 5
  def of(
          allocatorName: _root_.scala.Predef.String,
          totalBytes: _root_.scala.Long,
          peakBytes: _root_.scala.Long,
          liveBytes: _root_.scala.Long,
          allocationRecords: _root_.scala.Seq[AllocationRecord],
          allocatorBytesInUse: _root_.scala.Long
  ): AllocatorMemoryUsed = AllocatorMemoryUsed(
    allocatorName,
    totalBytes,
    peakBytes,
    liveBytes,
    allocationRecords,
    allocatorBytesInUse
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.AllocatorMemoryUsed])
}
