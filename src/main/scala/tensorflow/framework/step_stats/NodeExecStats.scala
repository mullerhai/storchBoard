// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package tensorflow.framework.step_stats

import tensorflow.framework.allocation_description.AllocationDescription
import tensorflow.framework.{allocation_description, step_stats}

/** Time/size stats recorded for a single execution of a graph node.
  *
  * @param nodeName
  *   TODO(tucker): Use some more compact form of node identity than
  *   the full string name.  Either all processes should agree on a
  *   global id (cost_id?) for each node, or we should use a hash of
  *   the name.
  */
@SerialVersionUID(0L)
final case class NodeExecStats(
                                nodeName: _root_.scala.Predef.String = "",
                                allStartMicros: _root_.scala.Long = 0L,
                                opStartRelMicros: _root_.scala.Long = 0L,
                                opEndRelMicros: _root_.scala.Long = 0L,
                                allEndRelMicros: _root_.scala.Long = 0L,
                                memory: _root_.scala.Seq[AllocatorMemoryUsed] = _root_.scala.Seq.empty,
                                output: _root_.scala.Seq[NodeOutput] = _root_.scala.Seq.empty,
                                timelineLabel: _root_.scala.Predef.String = "",
                                scheduledMicros: _root_.scala.Long = 0L,
                                threadId: _root_.scala.Int = 0,
                                referencedTensor: _root_.scala.Seq[AllocationDescription] = _root_.scala.Seq.empty,
                                memoryStats: _root_.scala.Option[MemoryStats] = _root_.scala.None,
                                allStartNanos: _root_.scala.Long = 0L,
                                opStartRelNanos: _root_.scala.Long = 0L,
                                opEndRelNanos: _root_.scala.Long = 0L,
                                allEndRelNanos: _root_.scala.Long = 0L,
                                scheduledNanos: _root_.scala.Long = 0L,
                                unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[NodeExecStats] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = nodeName
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
        }
      };
      
      {
        val __value = allStartMicros
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(2, __value)
        }
      };
      
      {
        val __value = opStartRelMicros
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(3, __value)
        }
      };
      
      {
        val __value = opEndRelMicros
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(4, __value)
        }
      };
      
      {
        val __value = allEndRelMicros
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(5, __value)
        }
      };
      memory.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      output.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      
      {
        val __value = timelineLabel
        if (!__value.isEmpty) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(8, __value)
        }
      };
      
      {
        val __value = scheduledMicros
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(9, __value)
        }
      };
      
      {
        val __value = threadId
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeUInt32Size(10, __value)
        }
      };
      referencedTensor.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      if (memoryStats.isDefined) {
        val __value = memoryStats.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      
      {
        val __value = allStartNanos
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(13, __value)
        }
      };
      
      {
        val __value = opStartRelNanos
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(14, __value)
        }
      };
      
      {
        val __value = opEndRelNanos
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(15, __value)
        }
      };
      
      {
        val __value = allEndRelNanos
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(16, __value)
        }
      };
      
      {
        val __value = scheduledNanos
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(17, __value)
        }
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = nodeName
        if (!__v.isEmpty) {
          _output__.writeString(1, __v)
        }
      };
      {
        val __v = allStartMicros
        if (__v != 0L) {
          _output__.writeInt64(2, __v)
        }
      };
      {
        val __v = opStartRelMicros
        if (__v != 0L) {
          _output__.writeInt64(3, __v)
        }
      };
      {
        val __v = opEndRelMicros
        if (__v != 0L) {
          _output__.writeInt64(4, __v)
        }
      };
      {
        val __v = allEndRelMicros
        if (__v != 0L) {
          _output__.writeInt64(5, __v)
        }
      };
      memory.foreach { __v =>
        val __m = __v
        _output__.writeTag(6, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      output.foreach { __v =>
        val __m = __v
        _output__.writeTag(7, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      {
        val __v = timelineLabel
        if (!__v.isEmpty) {
          _output__.writeString(8, __v)
        }
      };
      {
        val __v = scheduledMicros
        if (__v != 0L) {
          _output__.writeInt64(9, __v)
        }
      };
      {
        val __v = threadId
        if (__v != 0) {
          _output__.writeUInt32(10, __v)
        }
      };
      referencedTensor.foreach { __v =>
        val __m = __v
        _output__.writeTag(11, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      memoryStats.foreach { __v =>
        val __m = __v
        _output__.writeTag(12, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      {
        val __v = allStartNanos
        if (__v != 0L) {
          _output__.writeInt64(13, __v)
        }
      };
      {
        val __v = opStartRelNanos
        if (__v != 0L) {
          _output__.writeInt64(14, __v)
        }
      };
      {
        val __v = opEndRelNanos
        if (__v != 0L) {
          _output__.writeInt64(15, __v)
        }
      };
      {
        val __v = allEndRelNanos
        if (__v != 0L) {
          _output__.writeInt64(16, __v)
        }
      };
      {
        val __v = scheduledNanos
        if (__v != 0L) {
          _output__.writeInt64(17, __v)
        }
      };
      unknownFields.writeTo(_output__)
    }
    def withNodeName(__v: _root_.scala.Predef.String): NodeExecStats = copy(nodeName = __v)
    def withAllStartMicros(__v: _root_.scala.Long): NodeExecStats = copy(allStartMicros = __v)
    def withOpStartRelMicros(__v: _root_.scala.Long): NodeExecStats = copy(opStartRelMicros = __v)
    def withOpEndRelMicros(__v: _root_.scala.Long): NodeExecStats = copy(opEndRelMicros = __v)
    def withAllEndRelMicros(__v: _root_.scala.Long): NodeExecStats = copy(allEndRelMicros = __v)
    def clearMemory = copy(memory = _root_.scala.Seq.empty)
    def addMemory(__vs: AllocatorMemoryUsed *): NodeExecStats = addAllMemory(__vs)
    def addAllMemory(__vs: Iterable[AllocatorMemoryUsed]): NodeExecStats = copy(memory = memory ++ __vs)
    def withMemory(__v: _root_.scala.Seq[AllocatorMemoryUsed]): NodeExecStats = copy(memory = __v)
    def clearOutput = copy(output = _root_.scala.Seq.empty)
    def addOutput(__vs: NodeOutput *): NodeExecStats = addAllOutput(__vs)
    def addAllOutput(__vs: Iterable[NodeOutput]): NodeExecStats = copy(output = output ++ __vs)
    def withOutput(__v: _root_.scala.Seq[NodeOutput]): NodeExecStats = copy(output = __v)
    def withTimelineLabel(__v: _root_.scala.Predef.String): NodeExecStats = copy(timelineLabel = __v)
    def withScheduledMicros(__v: _root_.scala.Long): NodeExecStats = copy(scheduledMicros = __v)
    def withThreadId(__v: _root_.scala.Int): NodeExecStats = copy(threadId = __v)
    def clearReferencedTensor = copy(referencedTensor = _root_.scala.Seq.empty)
    def addReferencedTensor(__vs: AllocationDescription *): NodeExecStats = addAllReferencedTensor(__vs)
    def addAllReferencedTensor(__vs: Iterable[AllocationDescription]): NodeExecStats = copy(referencedTensor = referencedTensor ++ __vs)
    def withReferencedTensor(__v: _root_.scala.Seq[AllocationDescription]): NodeExecStats = copy(referencedTensor = __v)
    def getMemoryStats: MemoryStats = memoryStats.getOrElse(step_stats.MemoryStats.defaultInstance)
    def clearMemoryStats: NodeExecStats = copy(memoryStats = _root_.scala.None)
    def withMemoryStats(__v: MemoryStats): NodeExecStats = copy(memoryStats = Option(__v))
    def withAllStartNanos(__v: _root_.scala.Long): NodeExecStats = copy(allStartNanos = __v)
    def withOpStartRelNanos(__v: _root_.scala.Long): NodeExecStats = copy(opStartRelNanos = __v)
    def withOpEndRelNanos(__v: _root_.scala.Long): NodeExecStats = copy(opEndRelNanos = __v)
    def withAllEndRelNanos(__v: _root_.scala.Long): NodeExecStats = copy(allEndRelNanos = __v)
    def withScheduledNanos(__v: _root_.scala.Long): NodeExecStats = copy(scheduledNanos = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = nodeName
          if (__t != "") __t else null
        }
        case 2 => {
          val __t = allStartMicros
          if (__t != 0L) __t else null
        }
        case 3 => {
          val __t = opStartRelMicros
          if (__t != 0L) __t else null
        }
        case 4 => {
          val __t = opEndRelMicros
          if (__t != 0L) __t else null
        }
        case 5 => {
          val __t = allEndRelMicros
          if (__t != 0L) __t else null
        }
        case 6 => memory
        case 7 => output
        case 8 => {
          val __t = timelineLabel
          if (__t != "") __t else null
        }
        case 9 => {
          val __t = scheduledMicros
          if (__t != 0L) __t else null
        }
        case 10 => {
          val __t = threadId
          if (__t != 0) __t else null
        }
        case 11 => referencedTensor
        case 12 => memoryStats.orNull
        case 13 => {
          val __t = allStartNanos
          if (__t != 0L) __t else null
        }
        case 14 => {
          val __t = opStartRelNanos
          if (__t != 0L) __t else null
        }
        case 15 => {
          val __t = opEndRelNanos
          if (__t != 0L) __t else null
        }
        case 16 => {
          val __t = allEndRelNanos
          if (__t != 0L) __t else null
        }
        case 17 => {
          val __t = scheduledNanos
          if (__t != 0L) __t else null
        }
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PString(nodeName)
        case 2 => _root_.scalapb.descriptors.PLong(allStartMicros)
        case 3 => _root_.scalapb.descriptors.PLong(opStartRelMicros)
        case 4 => _root_.scalapb.descriptors.PLong(opEndRelMicros)
        case 5 => _root_.scalapb.descriptors.PLong(allEndRelMicros)
        case 6 => _root_.scalapb.descriptors.PRepeated(memory.iterator.map(_.toPMessage).toVector)
        case 7 => _root_.scalapb.descriptors.PRepeated(output.iterator.map(_.toPMessage).toVector)
        case 8 => _root_.scalapb.descriptors.PString(timelineLabel)
        case 9 => _root_.scalapb.descriptors.PLong(scheduledMicros)
        case 10 => _root_.scalapb.descriptors.PInt(threadId)
        case 11 => _root_.scalapb.descriptors.PRepeated(referencedTensor.iterator.map(_.toPMessage).toVector)
        case 12 => memoryStats.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 13 => _root_.scalapb.descriptors.PLong(allStartNanos)
        case 14 => _root_.scalapb.descriptors.PLong(opStartRelNanos)
        case 15 => _root_.scalapb.descriptors.PLong(opEndRelNanos)
        case 16 => _root_.scalapb.descriptors.PLong(allEndRelNanos)
        case 17 => _root_.scalapb.descriptors.PLong(scheduledNanos)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: NodeExecStats.type = step_stats.NodeExecStats
    // @@protoc_insertion_point(GeneratedMessage[tensorboard.NodeExecStats])
}

object NodeExecStats extends scalapb.GeneratedMessageCompanion[NodeExecStats] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[NodeExecStats] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): NodeExecStats = {
    var __nodeName: _root_.scala.Predef.String = ""
    var __allStartMicros: _root_.scala.Long = 0L
    var __opStartRelMicros: _root_.scala.Long = 0L
    var __opEndRelMicros: _root_.scala.Long = 0L
    var __allEndRelMicros: _root_.scala.Long = 0L
    val __memory: _root_.scala.collection.immutable.VectorBuilder[AllocatorMemoryUsed] = new _root_.scala.collection.immutable.VectorBuilder[AllocatorMemoryUsed]
    val __output: _root_.scala.collection.immutable.VectorBuilder[NodeOutput] = new _root_.scala.collection.immutable.VectorBuilder[NodeOutput]
    var __timelineLabel: _root_.scala.Predef.String = ""
    var __scheduledMicros: _root_.scala.Long = 0L
    var __threadId: _root_.scala.Int = 0
    val __referencedTensor: _root_.scala.collection.immutable.VectorBuilder[AllocationDescription] = new _root_.scala.collection.immutable.VectorBuilder[AllocationDescription]
    var __memoryStats: _root_.scala.Option[MemoryStats] = _root_.scala.None
    var __allStartNanos: _root_.scala.Long = 0L
    var __opStartRelNanos: _root_.scala.Long = 0L
    var __opEndRelNanos: _root_.scala.Long = 0L
    var __allEndRelNanos: _root_.scala.Long = 0L
    var __scheduledNanos: _root_.scala.Long = 0L
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __nodeName = _input__.readStringRequireUtf8()
        case 16 =>
          __allStartMicros = _input__.readInt64()
        case 24 =>
          __opStartRelMicros = _input__.readInt64()
        case 32 =>
          __opEndRelMicros = _input__.readInt64()
        case 40 =>
          __allEndRelMicros = _input__.readInt64()
        case 50 =>
          __memory += _root_.scalapb.LiteParser.readMessage[AllocatorMemoryUsed](_input__)
        case 58 =>
          __output += _root_.scalapb.LiteParser.readMessage[NodeOutput](_input__)
        case 66 =>
          __timelineLabel = _input__.readStringRequireUtf8()
        case 72 =>
          __scheduledMicros = _input__.readInt64()
        case 80 =>
          __threadId = _input__.readUInt32()
        case 90 =>
          __referencedTensor += _root_.scalapb.LiteParser.readMessage[AllocationDescription](_input__)
        case 98 =>
          __memoryStats = _root_.scala.Option(__memoryStats.fold(_root_.scalapb.LiteParser.readMessage[MemoryStats](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 104 =>
          __allStartNanos = _input__.readInt64()
        case 112 =>
          __opStartRelNanos = _input__.readInt64()
        case 120 =>
          __opEndRelNanos = _input__.readInt64()
        case 128 =>
          __allEndRelNanos = _input__.readInt64()
        case 136 =>
          __scheduledNanos = _input__.readInt64()
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    NodeExecStats(
        nodeName = __nodeName,
        allStartMicros = __allStartMicros,
        opStartRelMicros = __opStartRelMicros,
        opEndRelMicros = __opEndRelMicros,
        allEndRelMicros = __allEndRelMicros,
        memory = __memory.result(),
        output = __output.result(),
        timelineLabel = __timelineLabel,
        scheduledMicros = __scheduledMicros,
        threadId = __threadId,
        referencedTensor = __referencedTensor.result(),
        memoryStats = __memoryStats,
        allStartNanos = __allStartNanos,
        opStartRelNanos = __opStartRelNanos,
        opEndRelNanos = __opEndRelNanos,
        allEndRelNanos = __allEndRelNanos,
        scheduledNanos = __scheduledNanos,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[NodeExecStats] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      NodeExecStats(
        nodeName = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        allStartMicros = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        opStartRelMicros = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        opEndRelMicros = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        allEndRelMicros = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        memory = __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).map(_.as[_root_.scala.Seq[AllocatorMemoryUsed]]).getOrElse(_root_.scala.Seq.empty),
        output = __fieldsMap.get(scalaDescriptor.findFieldByNumber(7).get).map(_.as[_root_.scala.Seq[NodeOutput]]).getOrElse(_root_.scala.Seq.empty),
        timelineLabel = __fieldsMap.get(scalaDescriptor.findFieldByNumber(8).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
        scheduledMicros = __fieldsMap.get(scalaDescriptor.findFieldByNumber(9).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        threadId = __fieldsMap.get(scalaDescriptor.findFieldByNumber(10).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        referencedTensor = __fieldsMap.get(scalaDescriptor.findFieldByNumber(11).get).map(_.as[_root_.scala.Seq[AllocationDescription]]).getOrElse(_root_.scala.Seq.empty),
        memoryStats = __fieldsMap.get(scalaDescriptor.findFieldByNumber(12).get).flatMap(_.as[_root_.scala.Option[MemoryStats]]),
        allStartNanos = __fieldsMap.get(scalaDescriptor.findFieldByNumber(13).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        opStartRelNanos = __fieldsMap.get(scalaDescriptor.findFieldByNumber(14).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        opEndRelNanos = __fieldsMap.get(scalaDescriptor.findFieldByNumber(15).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        allEndRelNanos = __fieldsMap.get(scalaDescriptor.findFieldByNumber(16).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        scheduledNanos = __fieldsMap.get(scalaDescriptor.findFieldByNumber(17).get).map(_.as[_root_.scala.Long]).getOrElse(0L)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.step_stats.StepStatsProto.javaDescriptor.getMessageTypes().get(4)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.step_stats.StepStatsProto.scalaDescriptor.messages(4)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 6 => __out = step_stats.AllocatorMemoryUsed
      case 7 => __out = step_stats.NodeOutput
      case 11 => __out = allocation_description.AllocationDescription
      case 12 => __out = step_stats.MemoryStats
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = NodeExecStats(
    nodeName = "",
    allStartMicros = 0L,
    opStartRelMicros = 0L,
    opEndRelMicros = 0L,
    allEndRelMicros = 0L,
    memory = _root_.scala.Seq.empty,
    output = _root_.scala.Seq.empty,
    timelineLabel = "",
    scheduledMicros = 0L,
    threadId = 0,
    referencedTensor = _root_.scala.Seq.empty,
    memoryStats = _root_.scala.None,
    allStartNanos = 0L,
    opStartRelNanos = 0L,
    opEndRelNanos = 0L,
    allEndRelNanos = 0L,
    scheduledNanos = 0L
  )
  implicit class NodeExecStatsLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, NodeExecStats]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, NodeExecStats](_l) {
    def nodeName: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.nodeName)((c_, f_) => c_.copy(nodeName = f_))
    def allStartMicros: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.allStartMicros)((c_, f_) => c_.copy(allStartMicros = f_))
    def opStartRelMicros: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.opStartRelMicros)((c_, f_) => c_.copy(opStartRelMicros = f_))
    def opEndRelMicros: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.opEndRelMicros)((c_, f_) => c_.copy(opEndRelMicros = f_))
    def allEndRelMicros: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.allEndRelMicros)((c_, f_) => c_.copy(allEndRelMicros = f_))
    def memory: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[AllocatorMemoryUsed]] = field(_.memory)((c_, f_) => c_.copy(memory = f_))
    def output: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[NodeOutput]] = field(_.output)((c_, f_) => c_.copy(output = f_))
    def timelineLabel: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.timelineLabel)((c_, f_) => c_.copy(timelineLabel = f_))
    def scheduledMicros: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.scheduledMicros)((c_, f_) => c_.copy(scheduledMicros = f_))
    def threadId: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.threadId)((c_, f_) => c_.copy(threadId = f_))
    def referencedTensor: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[AllocationDescription]] = field(_.referencedTensor)((c_, f_) => c_.copy(referencedTensor = f_))
    def memoryStats: _root_.scalapb.lenses.Lens[UpperPB, MemoryStats] = field(_.getMemoryStats)((c_, f_) => c_.copy(memoryStats = _root_.scala.Option(f_)))
    def optionalMemoryStats: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[MemoryStats]] = field(_.memoryStats)((c_, f_) => c_.copy(memoryStats = f_))
    def allStartNanos: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.allStartNanos)((c_, f_) => c_.copy(allStartNanos = f_))
    def opStartRelNanos: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.opStartRelNanos)((c_, f_) => c_.copy(opStartRelNanos = f_))
    def opEndRelNanos: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.opEndRelNanos)((c_, f_) => c_.copy(opEndRelNanos = f_))
    def allEndRelNanos: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.allEndRelNanos)((c_, f_) => c_.copy(allEndRelNanos = f_))
    def scheduledNanos: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.scheduledNanos)((c_, f_) => c_.copy(scheduledNanos = f_))
  }
  final val NODE_NAME_FIELD_NUMBER = 1
  final val ALL_START_MICROS_FIELD_NUMBER = 2
  final val OP_START_REL_MICROS_FIELD_NUMBER = 3
  final val OP_END_REL_MICROS_FIELD_NUMBER = 4
  final val ALL_END_REL_MICROS_FIELD_NUMBER = 5
  final val MEMORY_FIELD_NUMBER = 6
  final val OUTPUT_FIELD_NUMBER = 7
  final val TIMELINE_LABEL_FIELD_NUMBER = 8
  final val SCHEDULED_MICROS_FIELD_NUMBER = 9
  final val THREAD_ID_FIELD_NUMBER = 10
  final val REFERENCED_TENSOR_FIELD_NUMBER = 11
  final val MEMORY_STATS_FIELD_NUMBER = 12
  final val ALL_START_NANOS_FIELD_NUMBER = 13
  final val OP_START_REL_NANOS_FIELD_NUMBER = 14
  final val OP_END_REL_NANOS_FIELD_NUMBER = 15
  final val ALL_END_REL_NANOS_FIELD_NUMBER = 16
  final val SCHEDULED_NANOS_FIELD_NUMBER = 17
  def of(
          nodeName: _root_.scala.Predef.String,
          allStartMicros: _root_.scala.Long,
          opStartRelMicros: _root_.scala.Long,
          opEndRelMicros: _root_.scala.Long,
          allEndRelMicros: _root_.scala.Long,
          memory: _root_.scala.Seq[AllocatorMemoryUsed],
          output: _root_.scala.Seq[NodeOutput],
          timelineLabel: _root_.scala.Predef.String,
          scheduledMicros: _root_.scala.Long,
          threadId: _root_.scala.Int,
          referencedTensor: _root_.scala.Seq[AllocationDescription],
          memoryStats: _root_.scala.Option[MemoryStats],
          allStartNanos: _root_.scala.Long,
          opStartRelNanos: _root_.scala.Long,
          opEndRelNanos: _root_.scala.Long,
          allEndRelNanos: _root_.scala.Long,
          scheduledNanos: _root_.scala.Long
  ): NodeExecStats = NodeExecStats(
    nodeName,
    allStartMicros,
    opStartRelMicros,
    opEndRelMicros,
    allEndRelMicros,
    memory,
    output,
    timelineLabel,
    scheduledMicros,
    threadId,
    referencedTensor,
    memoryStats,
    allStartNanos,
    opStartRelNanos,
    opEndRelNanos,
    allEndRelNanos,
    scheduledNanos
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.NodeExecStats])
}
