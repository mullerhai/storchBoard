// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package tensorboard.tfprof_log

/** A proto representation of the profiler's profile.
  * It allows serialization, shipping around and deserialization of the profiles.
  *
  * Please don't depend on the internals of the profile proto.
  *
  * @param hasTrace
  *   Whether or not has code traces.
  * @param missAcceleratorStream
  *   Whether or not the TF device tracer fails to return accelerator
  *   information (which could lead to 0 accelerator execution time).
  * @param steps
  *   Traced steps.
  * @param idToString
  *   Maps from id of CodeDef file,function,line to its string
  *   In the future can also map other id of other fields to string.
  */
@SerialVersionUID(0L)
final case class ProfileProto(
    nodes: _root_.scala.collection.immutable.Map[_root_.scala.Long, tensorboard.tfprof_log.ProfileNode] = _root_.scala.collection.immutable.Map.empty,
    hasTrace: _root_.scala.Boolean = false,
    missAcceleratorStream: _root_.scala.Boolean = false,
    steps: _root_.scala.Seq[_root_.scala.Long] = _root_.scala.Seq.empty,
    idToString: _root_.scala.collection.immutable.Map[_root_.scala.Long, _root_.scala.Predef.String] = _root_.scala.collection.immutable.Map.empty,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[ProfileProto] {
    private[this] def stepsSerializedSize = {
      if (__stepsSerializedSizeField == 0) __stepsSerializedSizeField = {
        var __s: _root_.scala.Int = 0
        steps.foreach(__i => __s += _root_.com.google.protobuf.CodedOutputStream.computeInt64SizeNoTag(__i))
        __s
      }
      __stepsSerializedSizeField
    }
    @transient private[this] var __stepsSerializedSizeField: _root_.scala.Int = 0
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      nodes.foreach { __item =>
        val __value = tensorboard.tfprof_log.ProfileProto._typemapper_nodes.toBase(__item)
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      
      {
        val __value = hasTrace
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(2, __value)
        }
      };
      
      {
        val __value = missAcceleratorStream
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(5, __value)
        }
      };
      if (steps.nonEmpty) {
        val __localsize = stepsSerializedSize
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__localsize) + __localsize
      }
      idToString.foreach { __item =>
        val __value = tensorboard.tfprof_log.ProfileProto._typemapper_idToString.toBase(__item)
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      nodes.foreach { __v =>
        val __m = tensorboard.tfprof_log.ProfileProto._typemapper_nodes.toBase(__v)
        _output__.writeTag(1, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      {
        val __v = hasTrace
        if (__v != false) {
          _output__.writeBool(2, __v)
        }
      };
      if (steps.nonEmpty) {
        _output__.writeTag(3, 2)
        _output__.writeUInt32NoTag(stepsSerializedSize)
        steps.foreach(_output__.writeInt64NoTag)
      };
      idToString.foreach { __v =>
        val __m = tensorboard.tfprof_log.ProfileProto._typemapper_idToString.toBase(__v)
        _output__.writeTag(4, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      {
        val __v = missAcceleratorStream
        if (__v != false) {
          _output__.writeBool(5, __v)
        }
      };
      unknownFields.writeTo(_output__)
    }
    def clearNodes = copy(nodes = _root_.scala.collection.immutable.Map.empty)
    def addNodes(__vs: (_root_.scala.Long, tensorboard.tfprof_log.ProfileNode) *): ProfileProto = addAllNodes(__vs)
    def addAllNodes(__vs: Iterable[(_root_.scala.Long, tensorboard.tfprof_log.ProfileNode)]): ProfileProto = copy(nodes = nodes ++ __vs)
    def withNodes(__v: _root_.scala.collection.immutable.Map[_root_.scala.Long, tensorboard.tfprof_log.ProfileNode]): ProfileProto = copy(nodes = __v)
    def withHasTrace(__v: _root_.scala.Boolean): ProfileProto = copy(hasTrace = __v)
    def withMissAcceleratorStream(__v: _root_.scala.Boolean): ProfileProto = copy(missAcceleratorStream = __v)
    def clearSteps = copy(steps = _root_.scala.Seq.empty)
    def addSteps(__vs: _root_.scala.Long *): ProfileProto = addAllSteps(__vs)
    def addAllSteps(__vs: Iterable[_root_.scala.Long]): ProfileProto = copy(steps = steps ++ __vs)
    def withSteps(__v: _root_.scala.Seq[_root_.scala.Long]): ProfileProto = copy(steps = __v)
    def clearIdToString = copy(idToString = _root_.scala.collection.immutable.Map.empty)
    def addIdToString(__vs: (_root_.scala.Long, _root_.scala.Predef.String) *): ProfileProto = addAllIdToString(__vs)
    def addAllIdToString(__vs: Iterable[(_root_.scala.Long, _root_.scala.Predef.String)]): ProfileProto = copy(idToString = idToString ++ __vs)
    def withIdToString(__v: _root_.scala.collection.immutable.Map[_root_.scala.Long, _root_.scala.Predef.String]): ProfileProto = copy(idToString = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => nodes.iterator.map(tensorboard.tfprof_log.ProfileProto._typemapper_nodes.toBase(_)).toSeq
        case 2 => {
          val __t = hasTrace
          if (__t != false) __t else null
        }
        case 5 => {
          val __t = missAcceleratorStream
          if (__t != false) __t else null
        }
        case 3 => steps
        case 4 => idToString.iterator.map(tensorboard.tfprof_log.ProfileProto._typemapper_idToString.toBase(_)).toSeq
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PRepeated(nodes.iterator.map(tensorboard.tfprof_log.ProfileProto._typemapper_nodes.toBase(_).toPMessage).toVector)
        case 2 => _root_.scalapb.descriptors.PBoolean(hasTrace)
        case 5 => _root_.scalapb.descriptors.PBoolean(missAcceleratorStream)
        case 3 => _root_.scalapb.descriptors.PRepeated(steps.iterator.map(_root_.scalapb.descriptors.PLong(_)).toVector)
        case 4 => _root_.scalapb.descriptors.PRepeated(idToString.iterator.map(tensorboard.tfprof_log.ProfileProto._typemapper_idToString.toBase(_).toPMessage).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: tensorboard.tfprof_log.ProfileProto.type = tensorboard.tfprof_log.ProfileProto
    // @@protoc_insertion_point(GeneratedMessage[tensorboard.ProfileProto])
}

object ProfileProto extends scalapb.GeneratedMessageCompanion[tensorboard.tfprof_log.ProfileProto] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[tensorboard.tfprof_log.ProfileProto] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): tensorboard.tfprof_log.ProfileProto = {
    val __nodes: _root_.scala.collection.mutable.Builder[(_root_.scala.Long, tensorboard.tfprof_log.ProfileNode), _root_.scala.collection.immutable.Map[_root_.scala.Long, tensorboard.tfprof_log.ProfileNode]] = _root_.scala.collection.immutable.Map.newBuilder[_root_.scala.Long, tensorboard.tfprof_log.ProfileNode]
    var __hasTrace: _root_.scala.Boolean = false
    var __missAcceleratorStream: _root_.scala.Boolean = false
    val __steps: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long] = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Long]
    val __idToString: _root_.scala.collection.mutable.Builder[(_root_.scala.Long, _root_.scala.Predef.String), _root_.scala.collection.immutable.Map[_root_.scala.Long, _root_.scala.Predef.String]] = _root_.scala.collection.immutable.Map.newBuilder[_root_.scala.Long, _root_.scala.Predef.String]
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __nodes += tensorboard.tfprof_log.ProfileProto._typemapper_nodes.toCustom(_root_.scalapb.LiteParser.readMessage[tensorboard.tfprof_log.ProfileProto.NodesEntry](_input__))
        case 16 =>
          __hasTrace = _input__.readBool()
        case 40 =>
          __missAcceleratorStream = _input__.readBool()
        case 24 =>
          __steps += _input__.readInt64()
        case 26 => {
          val length = _input__.readRawVarint32()
          val oldLimit = _input__.pushLimit(length)
          while (_input__.getBytesUntilLimit > 0) {
            __steps += _input__.readInt64()
          }
          _input__.popLimit(oldLimit)
        }
        case 34 =>
          __idToString += tensorboard.tfprof_log.ProfileProto._typemapper_idToString.toCustom(_root_.scalapb.LiteParser.readMessage[tensorboard.tfprof_log.ProfileProto.IdToStringEntry](_input__))
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    tensorboard.tfprof_log.ProfileProto(
        nodes = __nodes.result(),
        hasTrace = __hasTrace,
        missAcceleratorStream = __missAcceleratorStream,
        steps = __steps.result(),
        idToString = __idToString.result(),
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[tensorboard.tfprof_log.ProfileProto] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      tensorboard.tfprof_log.ProfileProto(
        nodes = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Seq[tensorboard.tfprof_log.ProfileProto.NodesEntry]]).getOrElse(_root_.scala.Seq.empty).iterator.map(tensorboard.tfprof_log.ProfileProto._typemapper_nodes.toCustom(_)).toMap,
        hasTrace = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        missAcceleratorStream = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        steps = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Seq[_root_.scala.Long]]).getOrElse(_root_.scala.Seq.empty),
        idToString = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Seq[tensorboard.tfprof_log.ProfileProto.IdToStringEntry]]).getOrElse(_root_.scala.Seq.empty).iterator.map(tensorboard.tfprof_log.ProfileProto._typemapper_idToString.toCustom(_)).toMap
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = tensorboard.tfprof_log.TfprofLogProto.javaDescriptor.getMessageTypes().get(3)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = tensorboard.tfprof_log.TfprofLogProto.scalaDescriptor.messages(3)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 1 => __out = tensorboard.tfprof_log.ProfileProto.NodesEntry
      case 4 => __out = tensorboard.tfprof_log.ProfileProto.IdToStringEntry
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] =
    Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]](
      _root_.tensorboard.tfprof_log.ProfileProto.NodesEntry,
      _root_.tensorboard.tfprof_log.ProfileProto.IdToStringEntry
    )
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = tensorboard.tfprof_log.ProfileProto(
    nodes = _root_.scala.collection.immutable.Map.empty,
    hasTrace = false,
    missAcceleratorStream = false,
    steps = _root_.scala.Seq.empty,
    idToString = _root_.scala.collection.immutable.Map.empty
  )
  @SerialVersionUID(0L)
  final case class NodesEntry(
      key: _root_.scala.Long = 0L,
      value: _root_.scala.Option[tensorboard.tfprof_log.ProfileNode] = _root_.scala.None,
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[NodesEntry] {
      @transient
      private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
      private[this] def __computeSerializedSize(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = key
          if (__value != 0L) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(1, __value)
          }
        };
        if (value.isDefined) {
          val __value = value.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var __size = __serializedSizeMemoized
        if (__size == 0) {
          __size = __computeSerializedSize() + 1
          __serializedSizeMemoized = __size
        }
        __size - 1
        
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = key
          if (__v != 0L) {
            _output__.writeInt64(1, __v)
          }
        };
        value.foreach { __v =>
          val __m = __v
          _output__.writeTag(2, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        unknownFields.writeTo(_output__)
      }
      def withKey(__v: _root_.scala.Long): NodesEntry = copy(key = __v)
      def getValue: tensorboard.tfprof_log.ProfileNode = value.getOrElse(tensorboard.tfprof_log.ProfileNode.defaultInstance)
      def clearValue: NodesEntry = copy(value = _root_.scala.None)
      def withValue(__v: tensorboard.tfprof_log.ProfileNode): NodesEntry = copy(value = Option(__v))
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = key
            if (__t != 0L) __t else null
          }
          case 2 => value.orNull
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PLong(key)
          case 2 => value.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion: tensorboard.tfprof_log.ProfileProto.NodesEntry.type = tensorboard.tfprof_log.ProfileProto.NodesEntry
      // @@protoc_insertion_point(GeneratedMessage[tensorboard.ProfileProto.NodesEntry])
  }
  
  object NodesEntry extends scalapb.GeneratedMessageCompanion[tensorboard.tfprof_log.ProfileProto.NodesEntry] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[tensorboard.tfprof_log.ProfileProto.NodesEntry] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): tensorboard.tfprof_log.ProfileProto.NodesEntry = {
      var __key: _root_.scala.Long = 0L
      var __value: _root_.scala.Option[tensorboard.tfprof_log.ProfileNode] = _root_.scala.None
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 8 =>
            __key = _input__.readInt64()
          case 18 =>
            __value = _root_.scala.Option(__value.fold(_root_.scalapb.LiteParser.readMessage[tensorboard.tfprof_log.ProfileNode](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      tensorboard.tfprof_log.ProfileProto.NodesEntry(
          key = __key,
          value = __value,
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[tensorboard.tfprof_log.ProfileProto.NodesEntry] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        tensorboard.tfprof_log.ProfileProto.NodesEntry(
          key = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
          value = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[tensorboard.tfprof_log.ProfileNode]])
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = tensorboard.tfprof_log.ProfileProto.javaDescriptor.getNestedTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = tensorboard.tfprof_log.ProfileProto.scalaDescriptor.nestedMessages(0)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
      var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
      (__number: @_root_.scala.unchecked) match {
        case 2 => __out = tensorboard.tfprof_log.ProfileNode
      }
      __out
    }
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = tensorboard.tfprof_log.ProfileProto.NodesEntry(
      key = 0L,
      value = _root_.scala.None
    )
    implicit class NodesEntryLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, tensorboard.tfprof_log.ProfileProto.NodesEntry]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, tensorboard.tfprof_log.ProfileProto.NodesEntry](_l) {
      def key: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.key)((c_, f_) => c_.copy(key = f_))
      def value: _root_.scalapb.lenses.Lens[UpperPB, tensorboard.tfprof_log.ProfileNode] = field(_.getValue)((c_, f_) => c_.copy(value = _root_.scala.Option(f_)))
      def optionalValue: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[tensorboard.tfprof_log.ProfileNode]] = field(_.value)((c_, f_) => c_.copy(value = f_))
    }
    final val KEY_FIELD_NUMBER = 1
    final val VALUE_FIELD_NUMBER = 2
    @transient
    implicit val keyValueMapper: _root_.scalapb.TypeMapper[tensorboard.tfprof_log.ProfileProto.NodesEntry, (_root_.scala.Long, tensorboard.tfprof_log.ProfileNode)] =
      _root_.scalapb.TypeMapper[tensorboard.tfprof_log.ProfileProto.NodesEntry, (_root_.scala.Long, tensorboard.tfprof_log.ProfileNode)](__m => (__m.key, __m.getValue))(__p => tensorboard.tfprof_log.ProfileProto.NodesEntry(__p._1, Some(__p._2)))
    def of(
      key: _root_.scala.Long,
      value: _root_.scala.Option[tensorboard.tfprof_log.ProfileNode]
    ): _root_.tensorboard.tfprof_log.ProfileProto.NodesEntry = _root_.tensorboard.tfprof_log.ProfileProto.NodesEntry(
      key,
      value
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.ProfileProto.NodesEntry])
  }
  
  @SerialVersionUID(0L)
  final case class IdToStringEntry(
      key: _root_.scala.Long = 0L,
      value: _root_.scala.Predef.String = "",
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[IdToStringEntry] {
      @transient
      private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
      private[this] def __computeSerializedSize(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = key
          if (__value != 0L) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(1, __value)
          }
        };
        
        {
          val __value = value
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(2, __value)
          }
        };
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var __size = __serializedSizeMemoized
        if (__size == 0) {
          __size = __computeSerializedSize() + 1
          __serializedSizeMemoized = __size
        }
        __size - 1
        
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = key
          if (__v != 0L) {
            _output__.writeInt64(1, __v)
          }
        };
        {
          val __v = value
          if (!__v.isEmpty) {
            _output__.writeString(2, __v)
          }
        };
        unknownFields.writeTo(_output__)
      }
      def withKey(__v: _root_.scala.Long): IdToStringEntry = copy(key = __v)
      def withValue(__v: _root_.scala.Predef.String): IdToStringEntry = copy(value = __v)
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = key
            if (__t != 0L) __t else null
          }
          case 2 => {
            val __t = value
            if (__t != "") __t else null
          }
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PLong(key)
          case 2 => _root_.scalapb.descriptors.PString(value)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion: tensorboard.tfprof_log.ProfileProto.IdToStringEntry.type = tensorboard.tfprof_log.ProfileProto.IdToStringEntry
      // @@protoc_insertion_point(GeneratedMessage[tensorboard.ProfileProto.IdToStringEntry])
  }
  
  object IdToStringEntry extends scalapb.GeneratedMessageCompanion[tensorboard.tfprof_log.ProfileProto.IdToStringEntry] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[tensorboard.tfprof_log.ProfileProto.IdToStringEntry] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): tensorboard.tfprof_log.ProfileProto.IdToStringEntry = {
      var __key: _root_.scala.Long = 0L
      var __value: _root_.scala.Predef.String = ""
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 8 =>
            __key = _input__.readInt64()
          case 18 =>
            __value = _input__.readStringRequireUtf8()
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      tensorboard.tfprof_log.ProfileProto.IdToStringEntry(
          key = __key,
          value = __value,
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[tensorboard.tfprof_log.ProfileProto.IdToStringEntry] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        tensorboard.tfprof_log.ProfileProto.IdToStringEntry(
          key = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
          value = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Predef.String]).getOrElse("")
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = tensorboard.tfprof_log.ProfileProto.javaDescriptor.getNestedTypes().get(1)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = tensorboard.tfprof_log.ProfileProto.scalaDescriptor.nestedMessages(1)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = throw new MatchError(__number)
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
    lazy val defaultInstance = tensorboard.tfprof_log.ProfileProto.IdToStringEntry(
      key = 0L,
      value = ""
    )
    implicit class IdToStringEntryLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, tensorboard.tfprof_log.ProfileProto.IdToStringEntry]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, tensorboard.tfprof_log.ProfileProto.IdToStringEntry](_l) {
      def key: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.key)((c_, f_) => c_.copy(key = f_))
      def value: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.value)((c_, f_) => c_.copy(value = f_))
    }
    final val KEY_FIELD_NUMBER = 1
    final val VALUE_FIELD_NUMBER = 2
    @transient
    implicit val keyValueMapper: _root_.scalapb.TypeMapper[tensorboard.tfprof_log.ProfileProto.IdToStringEntry, (_root_.scala.Long, _root_.scala.Predef.String)] =
      _root_.scalapb.TypeMapper[tensorboard.tfprof_log.ProfileProto.IdToStringEntry, (_root_.scala.Long, _root_.scala.Predef.String)](__m => (__m.key, __m.value))(__p => tensorboard.tfprof_log.ProfileProto.IdToStringEntry(__p._1, __p._2))
    def of(
      key: _root_.scala.Long,
      value: _root_.scala.Predef.String
    ): _root_.tensorboard.tfprof_log.ProfileProto.IdToStringEntry = _root_.tensorboard.tfprof_log.ProfileProto.IdToStringEntry(
      key,
      value
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.ProfileProto.IdToStringEntry])
  }
  
  implicit class ProfileProtoLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, tensorboard.tfprof_log.ProfileProto]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, tensorboard.tfprof_log.ProfileProto](_l) {
    def nodes: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.collection.immutable.Map[_root_.scala.Long, tensorboard.tfprof_log.ProfileNode]] = field(_.nodes)((c_, f_) => c_.copy(nodes = f_))
    def hasTrace: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.hasTrace)((c_, f_) => c_.copy(hasTrace = f_))
    def missAcceleratorStream: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.missAcceleratorStream)((c_, f_) => c_.copy(missAcceleratorStream = f_))
    def steps: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Long]] = field(_.steps)((c_, f_) => c_.copy(steps = f_))
    def idToString: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.collection.immutable.Map[_root_.scala.Long, _root_.scala.Predef.String]] = field(_.idToString)((c_, f_) => c_.copy(idToString = f_))
  }
  final val NODES_FIELD_NUMBER = 1
  final val HAS_TRACE_FIELD_NUMBER = 2
  final val MISS_ACCELERATOR_STREAM_FIELD_NUMBER = 5
  final val STEPS_FIELD_NUMBER = 3
  final val ID_TO_STRING_FIELD_NUMBER = 4
  @transient
  private[tfprof_log] val _typemapper_nodes: _root_.scalapb.TypeMapper[tensorboard.tfprof_log.ProfileProto.NodesEntry, (_root_.scala.Long, tensorboard.tfprof_log.ProfileNode)] = implicitly[_root_.scalapb.TypeMapper[tensorboard.tfprof_log.ProfileProto.NodesEntry, (_root_.scala.Long, tensorboard.tfprof_log.ProfileNode)]]
  @transient
  private[tfprof_log] val _typemapper_idToString: _root_.scalapb.TypeMapper[tensorboard.tfprof_log.ProfileProto.IdToStringEntry, (_root_.scala.Long, _root_.scala.Predef.String)] = implicitly[_root_.scalapb.TypeMapper[tensorboard.tfprof_log.ProfileProto.IdToStringEntry, (_root_.scala.Long, _root_.scala.Predef.String)]]
  def of(
    nodes: _root_.scala.collection.immutable.Map[_root_.scala.Long, tensorboard.tfprof_log.ProfileNode],
    hasTrace: _root_.scala.Boolean,
    missAcceleratorStream: _root_.scala.Boolean,
    steps: _root_.scala.Seq[_root_.scala.Long],
    idToString: _root_.scala.collection.immutable.Map[_root_.scala.Long, _root_.scala.Predef.String]
  ): _root_.tensorboard.tfprof_log.ProfileProto = _root_.tensorboard.tfprof_log.ProfileProto(
    nodes,
    hasTrace,
    missAcceleratorStream,
    steps,
    idToString
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.ProfileProto])
}
