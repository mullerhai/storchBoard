// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package org.tensorflow.framework.summary

sealed abstract class DataClass(val value: _root_.scala.Int) extends _root_.scalapb.GeneratedEnum {
  type EnumType = org.tensorflow.framework.summary.DataClass
  type RecognizedType = org.tensorflow.framework.summary.DataClass.Recognized
  def isDataClassUnknown: _root_.scala.Boolean = false
  def isDataClassScalar: _root_.scala.Boolean = false
  def isDataClassTensor: _root_.scala.Boolean = false
  def isDataClassBlobSequence: _root_.scala.Boolean = false
  def companion: _root_.scalapb.GeneratedEnumCompanion[DataClass] = org.tensorflow.framework.summary.DataClass
  final def asRecognized: _root_.scala.Option[org.tensorflow.framework.summary.DataClass.Recognized] = if (isUnrecognized) _root_.scala.None else _root_.scala.Some(this.asInstanceOf[org.tensorflow.framework.summary.DataClass.Recognized])
}

object DataClass extends _root_.scalapb.GeneratedEnumCompanion[DataClass] {
  sealed trait Recognized extends DataClass
  implicit def enumCompanion: _root_.scalapb.GeneratedEnumCompanion[DataClass] = this
  
  /** Unknown data class, used (implicitly) for legacy data. Will not be
    * processed by data ingestion pipelines.
    */
  @SerialVersionUID(0L)
  case object DATA_CLASS_UNKNOWN extends DataClass(0) with DataClass.Recognized {
    val index = 0
    val name = "DATA_CLASS_UNKNOWN"
    override def isDataClassUnknown: _root_.scala.Boolean = true
  }
  
  /** Scalar time series. Each `Value` for the corresponding tag must have
    * `tensor` set to a rank-0 tensor of type `DT_FLOAT` (float32).
    */
  @SerialVersionUID(0L)
  case object DATA_CLASS_SCALAR extends DataClass(1) with DataClass.Recognized {
    val index = 1
    val name = "DATA_CLASS_SCALAR"
    override def isDataClassScalar: _root_.scala.Boolean = true
  }
  
  /** Tensor time series. Each `Value` for the corresponding tag must have
    * `tensor` set. The tensor value is arbitrary, but should be small to
    * accommodate direct storage in database backends: an upper bound of a few
    * kilobytes is a reasonable rule of thumb.
    */
  @SerialVersionUID(0L)
  case object DATA_CLASS_TENSOR extends DataClass(2) with DataClass.Recognized {
    val index = 2
    val name = "DATA_CLASS_TENSOR"
    override def isDataClassTensor: _root_.scala.Boolean = true
  }
  
  /** Blob sequence time series. Each `Value` for the corresponding tag must
    * have `tensor` set to a rank-1 tensor of bytestring dtype.
    */
  @SerialVersionUID(0L)
  case object DATA_CLASS_BLOB_SEQUENCE extends DataClass(3) with DataClass.Recognized {
    val index = 3
    val name = "DATA_CLASS_BLOB_SEQUENCE"
    override def isDataClassBlobSequence: _root_.scala.Boolean = true
  }
  
  @SerialVersionUID(0L)
  final case class Unrecognized(unrecognizedValue: _root_.scala.Int) extends DataClass(unrecognizedValue) with _root_.scalapb.UnrecognizedEnum
  lazy val values: scala.collection.immutable.Seq[ValueType] = scala.collection.immutable.Seq(DATA_CLASS_UNKNOWN, DATA_CLASS_SCALAR, DATA_CLASS_TENSOR, DATA_CLASS_BLOB_SEQUENCE)
  def fromValue(__value: _root_.scala.Int): DataClass = __value match {
    case 0 => DATA_CLASS_UNKNOWN
    case 1 => DATA_CLASS_SCALAR
    case 2 => DATA_CLASS_TENSOR
    case 3 => DATA_CLASS_BLOB_SEQUENCE
    case __other => Unrecognized(__other)
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.EnumDescriptor = org.tensorflow.framework.summary.SummaryProto.javaDescriptor.getEnumTypes().get(0)
  def scalaDescriptor: _root_.scalapb.descriptors.EnumDescriptor = org.tensorflow.framework.summary.SummaryProto.scalaDescriptor.enums(0)
}