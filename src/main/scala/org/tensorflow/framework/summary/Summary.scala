// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package org.tensorflow.framework.summary

/** A Summary is a set of named values to be displayed by the
  * visualizer.
  *
  * Summaries are produced regularly during training, as controlled by
  * the "summary_interval_secs" attribute of the training operation.
  * Summaries are also produced at the end of an evaluation.
  *
  * @param value
  *   Set of values for the summary.
  */
@SerialVersionUID(0L)
final case class Summary(
    value: _root_.scala.Seq[org.tensorflow.framework.summary.Summary.Value] = _root_.scala.Seq.empty,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[Summary] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      value.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      value.foreach { __v =>
        val __m = __v
        _output__.writeTag(1, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      unknownFields.writeTo(_output__)
    }
    def clearValue = copy(value = _root_.scala.Seq.empty)
    def addValue(__vs: org.tensorflow.framework.summary.Summary.Value *): Summary = addAllValue(__vs)
    def addAllValue(__vs: Iterable[org.tensorflow.framework.summary.Summary.Value]): Summary = copy(value = value ++ __vs)
    def withValue(__v: _root_.scala.Seq[org.tensorflow.framework.summary.Summary.Value]): Summary = copy(value = __v)
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => value
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PRepeated(value.iterator.map(_.toPMessage).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: org.tensorflow.framework.summary.Summary.type = org.tensorflow.framework.summary.Summary
    // @@protoc_insertion_point(GeneratedMessage[tensorboard.Summary])
}

object Summary extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.summary.Summary] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.summary.Summary] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.summary.Summary = {
    val __value: _root_.scala.collection.immutable.VectorBuilder[org.tensorflow.framework.summary.Summary.Value] = new _root_.scala.collection.immutable.VectorBuilder[org.tensorflow.framework.summary.Summary.Value]
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __value += _root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.summary.Summary.Value](_input__)
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    org.tensorflow.framework.summary.Summary(
        value = __value.result(),
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.summary.Summary] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      org.tensorflow.framework.summary.Summary(
        value = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Seq[org.tensorflow.framework.summary.Summary.Value]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.summary.SummaryProto.javaDescriptor.getMessageTypes().get(2)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.summary.SummaryProto.scalaDescriptor.messages(2)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?]= {
    var __out: _root_.scalapb.GeneratedMessageCompanion[?]= null
    (__number: @_root_.scala.unchecked) match {
      case 1 => __out = org.tensorflow.framework.summary.Summary.Value
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] =
    Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]](
      _root_.org.tensorflow.framework.summary.Summary.Image,
      _root_.org.tensorflow.framework.summary.Summary.Audio,
      _root_.org.tensorflow.framework.summary.Summary.Value
    )
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?]= throw new MatchError(__fieldNumber)
  lazy val defaultInstance = org.tensorflow.framework.summary.Summary(
    value = _root_.scala.Seq.empty
  )
  /** @param height
    *   Dimensions of the image.
    * @param colorspace
    *   Valid colorspace values are
    *     1 - grayscale
    *     2 - grayscale + alpha
    *     3 - RGB
    *     4 - RGBA
    *     5 - DIGITAL_YUV
    *     6 - BGRA
    * @param encodedImageString
    *   Image data in encoded format.  All image formats supported by
    *   image_codec::CoderUtil can be stored here.
    */
  @SerialVersionUID(0L)
  final case class Image(
      height: _root_.scala.Int = 0,
      width: _root_.scala.Int = 0,
      colorspace: _root_.scala.Int = 0,
      encodedImageString: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY,
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[Image] {
      @transient
      private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
      private[this] def __computeSerializedSize(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = height
          if (__value != 0) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
          }
        };
        
        {
          val __value = width
          if (__value != 0) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(2, __value)
          }
        };
        
        {
          val __value = colorspace
          if (__value != 0) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(3, __value)
          }
        };
        
        {
          val __value = encodedImageString
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeBytesSize(4, __value)
          }
        };
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var __size = __serializedSizeMemoized
        if (__size == 0) {
          __size = __computeSerializedSize() + 1
          __serializedSizeMemoized = __size
        }
        __size - 1
        
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = height
          if (__v != 0) {
            _output__.writeInt32(1, __v)
          }
        };
        {
          val __v = width
          if (__v != 0) {
            _output__.writeInt32(2, __v)
          }
        };
        {
          val __v = colorspace
          if (__v != 0) {
            _output__.writeInt32(3, __v)
          }
        };
        {
          val __v = encodedImageString
          if (!__v.isEmpty) {
            _output__.writeBytes(4, __v)
          }
        };
        unknownFields.writeTo(_output__)
      }
      def withHeight(__v: _root_.scala.Int): Image = copy(height = __v)
      def withWidth(__v: _root_.scala.Int): Image = copy(width = __v)
      def withColorspace(__v: _root_.scala.Int): Image = copy(colorspace = __v)
      def withEncodedImageString(__v: _root_.com.google.protobuf.ByteString): Image = copy(encodedImageString = __v)
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = height
            if (__t != 0) __t else null
          }
          case 2 => {
            val __t = width
            if (__t != 0) __t else null
          }
          case 3 => {
            val __t = colorspace
            if (__t != 0) __t else null
          }
          case 4 => {
            val __t = encodedImageString
            if (__t != _root_.com.google.protobuf.ByteString.EMPTY) __t else null
          }
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PInt(height)
          case 2 => _root_.scalapb.descriptors.PInt(width)
          case 3 => _root_.scalapb.descriptors.PInt(colorspace)
          case 4 => _root_.scalapb.descriptors.PByteString(encodedImageString)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion: org.tensorflow.framework.summary.Summary.Image.type = org.tensorflow.framework.summary.Summary.Image
      // @@protoc_insertion_point(GeneratedMessage[tensorboard.Summary.Image])
  }
  
  object Image extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.summary.Summary.Image] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.summary.Summary.Image] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.summary.Summary.Image = {
      var __height: _root_.scala.Int = 0
      var __width: _root_.scala.Int = 0
      var __colorspace: _root_.scala.Int = 0
      var __encodedImageString: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 8 =>
            __height = _input__.readInt32()
          case 16 =>
            __width = _input__.readInt32()
          case 24 =>
            __colorspace = _input__.readInt32()
          case 34 =>
            __encodedImageString = _input__.readBytes()
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      org.tensorflow.framework.summary.Summary.Image(
          height = __height,
          width = __width,
          colorspace = __colorspace,
          encodedImageString = __encodedImageString,
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.summary.Summary.Image] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        org.tensorflow.framework.summary.Summary.Image(
          height = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
          width = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Int]).getOrElse(0),
          colorspace = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Int]).getOrElse(0),
          encodedImageString = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.com.google.protobuf.ByteString]).getOrElse(_root_.com.google.protobuf.ByteString.EMPTY)
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.summary.Summary.javaDescriptor.getNestedTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.summary.Summary.scalaDescriptor.nestedMessages(0)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?]= throw new MatchError(__number)
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?]= throw new MatchError(__fieldNumber)
    lazy val defaultInstance = org.tensorflow.framework.summary.Summary.Image(
      height = 0,
      width = 0,
      colorspace = 0,
      encodedImageString = _root_.com.google.protobuf.ByteString.EMPTY
    )
    implicit class ImageLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.summary.Summary.Image]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.summary.Summary.Image](_l) {
      def height: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.height)((c_, f_) => c_.copy(height = f_))
      def width: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.width)((c_, f_) => c_.copy(width = f_))
      def colorspace: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.colorspace)((c_, f_) => c_.copy(colorspace = f_))
      def encodedImageString: _root_.scalapb.lenses.Lens[UpperPB, _root_.com.google.protobuf.ByteString] = field(_.encodedImageString)((c_, f_) => c_.copy(encodedImageString = f_))
    }
    final val HEIGHT_FIELD_NUMBER = 1
    final val WIDTH_FIELD_NUMBER = 2
    final val COLORSPACE_FIELD_NUMBER = 3
    final val ENCODED_IMAGE_STRING_FIELD_NUMBER = 4
    def of(
      height: _root_.scala.Int,
      width: _root_.scala.Int,
      colorspace: _root_.scala.Int,
      encodedImageString: _root_.com.google.protobuf.ByteString
    ): _root_.org.tensorflow.framework.summary.Summary.Image = _root_.org.tensorflow.framework.summary.Summary.Image(
      height,
      width,
      colorspace,
      encodedImageString
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.Summary.Image])
  }
  
  /** @param sampleRate
    *   Sample rate of the audio in Hz.
    * @param numChannels
    *   Number of channels of audio.
    * @param lengthFrames
    *   Length of the audio in frames (samples per channel).
    * @param encodedAudioString
    *   Encoded audio data and its associated RFC 2045 content type (e.g.
    *   "audio/wav").
    */
  @SerialVersionUID(0L)
  final case class Audio(
      sampleRate: _root_.scala.Float = 0.0f,
      numChannels: _root_.scala.Long = 0L,
      lengthFrames: _root_.scala.Long = 0L,
      encodedAudioString: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY,
      contentType: _root_.scala.Predef.String = "",
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[Audio] {
      @transient
      private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
      private[this] def __computeSerializedSize(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = sampleRate
          if (__value != 0.0f) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeFloatSize(1, __value)
          }
        };
        
        {
          val __value = numChannels
          if (__value != 0L) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(2, __value)
          }
        };
        
        {
          val __value = lengthFrames
          if (__value != 0L) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(3, __value)
          }
        };
        
        {
          val __value = encodedAudioString
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeBytesSize(4, __value)
          }
        };
        
        {
          val __value = contentType
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(5, __value)
          }
        };
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var __size = __serializedSizeMemoized
        if (__size == 0) {
          __size = __computeSerializedSize() + 1
          __serializedSizeMemoized = __size
        }
        __size - 1
        
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = sampleRate
          if (__v != 0.0f) {
            _output__.writeFloat(1, __v)
          }
        };
        {
          val __v = numChannels
          if (__v != 0L) {
            _output__.writeInt64(2, __v)
          }
        };
        {
          val __v = lengthFrames
          if (__v != 0L) {
            _output__.writeInt64(3, __v)
          }
        };
        {
          val __v = encodedAudioString
          if (!__v.isEmpty) {
            _output__.writeBytes(4, __v)
          }
        };
        {
          val __v = contentType
          if (!__v.isEmpty) {
            _output__.writeString(5, __v)
          }
        };
        unknownFields.writeTo(_output__)
      }
      def withSampleRate(__v: _root_.scala.Float): Audio = copy(sampleRate = __v)
      def withNumChannels(__v: _root_.scala.Long): Audio = copy(numChannels = __v)
      def withLengthFrames(__v: _root_.scala.Long): Audio = copy(lengthFrames = __v)
      def withEncodedAudioString(__v: _root_.com.google.protobuf.ByteString): Audio = copy(encodedAudioString = __v)
      def withContentType(__v: _root_.scala.Predef.String): Audio = copy(contentType = __v)
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = sampleRate
            if (__t != 0.0f) __t else null
          }
          case 2 => {
            val __t = numChannels
            if (__t != 0L) __t else null
          }
          case 3 => {
            val __t = lengthFrames
            if (__t != 0L) __t else null
          }
          case 4 => {
            val __t = encodedAudioString
            if (__t != _root_.com.google.protobuf.ByteString.EMPTY) __t else null
          }
          case 5 => {
            val __t = contentType
            if (__t != "") __t else null
          }
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PFloat(sampleRate)
          case 2 => _root_.scalapb.descriptors.PLong(numChannels)
          case 3 => _root_.scalapb.descriptors.PLong(lengthFrames)
          case 4 => _root_.scalapb.descriptors.PByteString(encodedAudioString)
          case 5 => _root_.scalapb.descriptors.PString(contentType)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion: org.tensorflow.framework.summary.Summary.Audio.type = org.tensorflow.framework.summary.Summary.Audio
      // @@protoc_insertion_point(GeneratedMessage[tensorboard.Summary.Audio])
  }
  
  object Audio extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.summary.Summary.Audio] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.summary.Summary.Audio] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.summary.Summary.Audio = {
      var __sampleRate: _root_.scala.Float = 0.0f
      var __numChannels: _root_.scala.Long = 0L
      var __lengthFrames: _root_.scala.Long = 0L
      var __encodedAudioString: _root_.com.google.protobuf.ByteString = _root_.com.google.protobuf.ByteString.EMPTY
      var __contentType: _root_.scala.Predef.String = ""
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 13 =>
            __sampleRate = _input__.readFloat()
          case 16 =>
            __numChannels = _input__.readInt64()
          case 24 =>
            __lengthFrames = _input__.readInt64()
          case 34 =>
            __encodedAudioString = _input__.readBytes()
          case 42 =>
            __contentType = _input__.readStringRequireUtf8()
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      org.tensorflow.framework.summary.Summary.Audio(
          sampleRate = __sampleRate,
          numChannels = __numChannels,
          lengthFrames = __lengthFrames,
          encodedAudioString = __encodedAudioString,
          contentType = __contentType,
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.summary.Summary.Audio] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        org.tensorflow.framework.summary.Summary.Audio(
          sampleRate = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Float]).getOrElse(0.0f),
          numChannels = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
          lengthFrames = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
          encodedAudioString = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.com.google.protobuf.ByteString]).getOrElse(_root_.com.google.protobuf.ByteString.EMPTY),
          contentType = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Predef.String]).getOrElse("")
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.summary.Summary.javaDescriptor.getNestedTypes().get(1)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.summary.Summary.scalaDescriptor.nestedMessages(1)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?]= throw new MatchError(__number)
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?]= throw new MatchError(__fieldNumber)
    lazy val defaultInstance = org.tensorflow.framework.summary.Summary.Audio(
      sampleRate = 0.0f,
      numChannels = 0L,
      lengthFrames = 0L,
      encodedAudioString = _root_.com.google.protobuf.ByteString.EMPTY,
      contentType = ""
    )
    implicit class AudioLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.summary.Summary.Audio]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.summary.Summary.Audio](_l) {
      def sampleRate: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Float] = field(_.sampleRate)((c_, f_) => c_.copy(sampleRate = f_))
      def numChannels: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.numChannels)((c_, f_) => c_.copy(numChannels = f_))
      def lengthFrames: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.lengthFrames)((c_, f_) => c_.copy(lengthFrames = f_))
      def encodedAudioString: _root_.scalapb.lenses.Lens[UpperPB, _root_.com.google.protobuf.ByteString] = field(_.encodedAudioString)((c_, f_) => c_.copy(encodedAudioString = f_))
      def contentType: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.contentType)((c_, f_) => c_.copy(contentType = f_))
    }
    final val SAMPLE_RATE_FIELD_NUMBER = 1
    final val NUM_CHANNELS_FIELD_NUMBER = 2
    final val LENGTH_FRAMES_FIELD_NUMBER = 3
    final val ENCODED_AUDIO_STRING_FIELD_NUMBER = 4
    final val CONTENT_TYPE_FIELD_NUMBER = 5
    def of(
      sampleRate: _root_.scala.Float,
      numChannels: _root_.scala.Long,
      lengthFrames: _root_.scala.Long,
      encodedAudioString: _root_.com.google.protobuf.ByteString,
      contentType: _root_.scala.Predef.String
    ): _root_.org.tensorflow.framework.summary.Summary.Audio = _root_.org.tensorflow.framework.summary.Summary.Audio(
      sampleRate,
      numChannels,
      lengthFrames,
      encodedAudioString,
      contentType
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.Summary.Audio])
  }
  
  /** @param nodeName
    *   This field is deprecated and will not be set.
    * @param tag
    *   Tag name for the data. Used by TensorBoard plugins to organize data. Tags
    *   are often organized by scope (which contains slashes to convey
    *   hierarchy). For example: foo/bar/0
    * @param metadata
    *   Contains metadata on the summary value such as which plugins may use it.
    *   Take note that many summary values may lack a metadata field. This is
    *   because the FileWriter only keeps a metadata object on the first summary
    *   value with a certain tag for each tag. TensorBoard then remembers which
    *   tags are associated with which plugins. This saves space.
    */
  @SerialVersionUID(0L)
  final case class Value(
      nodeName: _root_.scala.Predef.String = "",
      tag: _root_.scala.Predef.String = "",
      metadata: _root_.scala.Option[org.tensorflow.framework.summary.SummaryMetadata] = _root_.scala.None,
      value: org.tensorflow.framework.summary.Summary.Value.Value = org.tensorflow.framework.summary.Summary.Value.Value.Empty,
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[Value] {
      @transient
      private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
      private[this] def __computeSerializedSize(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = nodeName
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(7, __value)
          }
        };
        
        {
          val __value = tag
          if (!__value.isEmpty) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeStringSize(1, __value)
          }
        };
        if (metadata.isDefined) {
          val __value = metadata.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        if (value.simpleValue.isDefined) {
          val __value = value.simpleValue.get
          __size += _root_.com.google.protobuf.CodedOutputStream.computeFloatSize(2, __value)
        };
        if (value.obsoleteOldStyleHistogram.isDefined) {
          val __value = value.obsoleteOldStyleHistogram.get
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBytesSize(3, __value)
        };
        if (value.image.isDefined) {
          val __value = value.image.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        if (value.histo.isDefined) {
          val __value = value.histo.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        if (value.audio.isDefined) {
          val __value = value.audio.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        if (value.tensor.isDefined) {
          val __value = value.tensor.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var __size = __serializedSizeMemoized
        if (__size == 0) {
          __size = __computeSerializedSize() + 1
          __serializedSizeMemoized = __size
        }
        __size - 1
        
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = tag
          if (!__v.isEmpty) {
            _output__.writeString(1, __v)
          }
        };
        value.simpleValue.foreach { __v =>
          val __m = __v
          _output__.writeFloat(2, __m)
        };
        value.obsoleteOldStyleHistogram.foreach { __v =>
          val __m = __v
          _output__.writeBytes(3, __m)
        };
        value.image.foreach { __v =>
          val __m = __v
          _output__.writeTag(4, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        value.histo.foreach { __v =>
          val __m = __v
          _output__.writeTag(5, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        value.audio.foreach { __v =>
          val __m = __v
          _output__.writeTag(6, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        {
          val __v = nodeName
          if (!__v.isEmpty) {
            _output__.writeString(7, __v)
          }
        };
        value.tensor.foreach { __v =>
          val __m = __v
          _output__.writeTag(8, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        metadata.foreach { __v =>
          val __m = __v
          _output__.writeTag(9, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        unknownFields.writeTo(_output__)
      }
      def withNodeName(__v: _root_.scala.Predef.String): Value = copy(nodeName = __v)
      def withTag(__v: _root_.scala.Predef.String): Value = copy(tag = __v)
      def getMetadata: org.tensorflow.framework.summary.SummaryMetadata = metadata.getOrElse(org.tensorflow.framework.summary.SummaryMetadata.defaultInstance)
      def clearMetadata: Value = copy(metadata = _root_.scala.None)
      def withMetadata(__v: org.tensorflow.framework.summary.SummaryMetadata): Value = copy(metadata = Option(__v))
      def getSimpleValue: _root_.scala.Float = value.simpleValue.getOrElse(0.0f)
      def withSimpleValue(__v: _root_.scala.Float): Value = copy(value = org.tensorflow.framework.summary.Summary.Value.Value.SimpleValue(__v))
      def getObsoleteOldStyleHistogram: _root_.com.google.protobuf.ByteString = value.obsoleteOldStyleHistogram.getOrElse(_root_.com.google.protobuf.ByteString.EMPTY)
      def withObsoleteOldStyleHistogram(__v: _root_.com.google.protobuf.ByteString): Value = copy(value = org.tensorflow.framework.summary.Summary.Value.Value.ObsoleteOldStyleHistogram(__v))
      def getImage: org.tensorflow.framework.summary.Summary.Image = value.image.getOrElse(org.tensorflow.framework.summary.Summary.Image.defaultInstance)
      def withImage(__v: org.tensorflow.framework.summary.Summary.Image): Value = copy(value = org.tensorflow.framework.summary.Summary.Value.Value.Image(__v))
      def getHisto: org.tensorflow.framework.histogram.HistogramProto = value.histo.getOrElse(org.tensorflow.framework.histogram.HistogramProto.defaultInstance)
      def withHisto(__v: org.tensorflow.framework.histogram.HistogramProto): Value = copy(value = org.tensorflow.framework.summary.Summary.Value.Value.Histo(__v))
      def getAudio: org.tensorflow.framework.summary.Summary.Audio = value.audio.getOrElse(org.tensorflow.framework.summary.Summary.Audio.defaultInstance)
      def withAudio(__v: org.tensorflow.framework.summary.Summary.Audio): Value = copy(value = org.tensorflow.framework.summary.Summary.Value.Value.Audio(__v))
      def getTensor: org.tensorflow.framework.tensor.TensorProto = value.tensor.getOrElse(org.tensorflow.framework.tensor.TensorProto.defaultInstance)
      def withTensor(__v: org.tensorflow.framework.tensor.TensorProto): Value = copy(value = org.tensorflow.framework.summary.Summary.Value.Value.Tensor(__v))
      def clearValue: Value = copy(value = org.tensorflow.framework.summary.Summary.Value.Value.Empty)
      def withValue(__v: org.tensorflow.framework.summary.Summary.Value.Value): Value = copy(value = __v)
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 7 => {
            val __t = nodeName
            if (__t != "") __t else null
          }
          case 1 => {
            val __t = tag
            if (__t != "") __t else null
          }
          case 9 => metadata.orNull
          case 2 => value.simpleValue.orNull
          case 3 => value.obsoleteOldStyleHistogram.orNull
          case 4 => value.image.orNull
          case 5 => value.histo.orNull
          case 6 => value.audio.orNull
          case 8 => value.tensor.orNull
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 7 => _root_.scalapb.descriptors.PString(nodeName)
          case 1 => _root_.scalapb.descriptors.PString(tag)
          case 9 => metadata.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
          case 2 => value.simpleValue.map(_root_.scalapb.descriptors.PFloat(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
          case 3 => value.obsoleteOldStyleHistogram.map(_root_.scalapb.descriptors.PByteString(_)).getOrElse(_root_.scalapb.descriptors.PEmpty)
          case 4 => value.image.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
          case 5 => value.histo.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
          case 6 => value.audio.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
          case 8 => value.tensor.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion: org.tensorflow.framework.summary.Summary.Value.type = org.tensorflow.framework.summary.Summary.Value
      // @@protoc_insertion_point(GeneratedMessage[tensorboard.Summary.Value])
  }
  
  object Value extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.summary.Summary.Value] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.summary.Summary.Value] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.summary.Summary.Value = {
      var __nodeName: _root_.scala.Predef.String = ""
      var __tag: _root_.scala.Predef.String = ""
      var __metadata: _root_.scala.Option[org.tensorflow.framework.summary.SummaryMetadata] = _root_.scala.None
      var __value: org.tensorflow.framework.summary.Summary.Value.Value = org.tensorflow.framework.summary.Summary.Value.Value.Empty
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 58 =>
            __nodeName = _input__.readStringRequireUtf8()
          case 10 =>
            __tag = _input__.readStringRequireUtf8()
          case 74 =>
            __metadata = _root_.scala.Option(__metadata.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.summary.SummaryMetadata](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
          case 21 =>
            __value = org.tensorflow.framework.summary.Summary.Value.Value.SimpleValue(_input__.readFloat())
          case 26 =>
            __value = org.tensorflow.framework.summary.Summary.Value.Value.ObsoleteOldStyleHistogram(_input__.readBytes())
          case 34 =>
            __value = org.tensorflow.framework.summary.Summary.Value.Value.Image(__value.image.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.summary.Summary.Image](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
          case 42 =>
            __value = org.tensorflow.framework.summary.Summary.Value.Value.Histo(__value.histo.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.histogram.HistogramProto](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
          case 50 =>
            __value = org.tensorflow.framework.summary.Summary.Value.Value.Audio(__value.audio.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.summary.Summary.Audio](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
          case 66 =>
            __value = org.tensorflow.framework.summary.Summary.Value.Value.Tensor(__value.tensor.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.tensor.TensorProto](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      org.tensorflow.framework.summary.Summary.Value(
          nodeName = __nodeName,
          tag = __tag,
          metadata = __metadata,
          value = __value,
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.summary.Summary.Value] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        org.tensorflow.framework.summary.Summary.Value(
          nodeName = __fieldsMap.get(scalaDescriptor.findFieldByNumber(7).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
          tag = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Predef.String]).getOrElse(""),
          metadata = __fieldsMap.get(scalaDescriptor.findFieldByNumber(9).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.summary.SummaryMetadata]]),
          value = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[_root_.scala.Float]]).map(org.tensorflow.framework.summary.Summary.Value.Value.SimpleValue(_))
              .orElse[org.tensorflow.framework.summary.Summary.Value.Value](__fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).flatMap(_.as[_root_.scala.Option[_root_.com.google.protobuf.ByteString]]).map(org.tensorflow.framework.summary.Summary.Value.Value.ObsoleteOldStyleHistogram(_)))
              .orElse[org.tensorflow.framework.summary.Summary.Value.Value](__fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.summary.Summary.Image]]).map(org.tensorflow.framework.summary.Summary.Value.Value.Image(_)))
              .orElse[org.tensorflow.framework.summary.Summary.Value.Value](__fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.histogram.HistogramProto]]).map(org.tensorflow.framework.summary.Summary.Value.Value.Histo(_)))
              .orElse[org.tensorflow.framework.summary.Summary.Value.Value](__fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.summary.Summary.Audio]]).map(org.tensorflow.framework.summary.Summary.Value.Value.Audio(_)))
              .orElse[org.tensorflow.framework.summary.Summary.Value.Value](__fieldsMap.get(scalaDescriptor.findFieldByNumber(8).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.tensor.TensorProto]]).map(org.tensorflow.framework.summary.Summary.Value.Value.Tensor(_)))
              .getOrElse(org.tensorflow.framework.summary.Summary.Value.Value.Empty)
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.summary.Summary.javaDescriptor.getNestedTypes().get(2)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.summary.Summary.scalaDescriptor.nestedMessages(2)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?]= {
      var __out: _root_.scalapb.GeneratedMessageCompanion[?]= null
      (__number: @_root_.scala.unchecked) match {
        case 9 => __out = org.tensorflow.framework.summary.SummaryMetadata
        case 4 => __out = org.tensorflow.framework.summary.Summary.Image
        case 5 => __out = org.tensorflow.framework.histogram.HistogramProto
        case 6 => __out = org.tensorflow.framework.summary.Summary.Audio
        case 8 => __out = org.tensorflow.framework.tensor.TensorProto
      }
      __out
    }
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] = Seq.empty
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?]= throw new MatchError(__fieldNumber)
    lazy val defaultInstance = org.tensorflow.framework.summary.Summary.Value(
      nodeName = "",
      tag = "",
      metadata = _root_.scala.None,
      value = org.tensorflow.framework.summary.Summary.Value.Value.Empty
    )
    sealed abstract class Value extends _root_.scalapb.GeneratedOneof {
      def isEmpty: _root_.scala.Boolean = false
      def isDefined: _root_.scala.Boolean = true
      def isSimpleValue: _root_.scala.Boolean = false
      def isObsoleteOldStyleHistogram: _root_.scala.Boolean = false
      def isImage: _root_.scala.Boolean = false
      def isHisto: _root_.scala.Boolean = false
      def isAudio: _root_.scala.Boolean = false
      def isTensor: _root_.scala.Boolean = false
      def simpleValue: _root_.scala.Option[_root_.scala.Float] = _root_.scala.None
      def obsoleteOldStyleHistogram: _root_.scala.Option[_root_.com.google.protobuf.ByteString] = _root_.scala.None
      def image: _root_.scala.Option[org.tensorflow.framework.summary.Summary.Image] = _root_.scala.None
      def histo: _root_.scala.Option[org.tensorflow.framework.histogram.HistogramProto] = _root_.scala.None
      def audio: _root_.scala.Option[org.tensorflow.framework.summary.Summary.Audio] = _root_.scala.None
      def tensor: _root_.scala.Option[org.tensorflow.framework.tensor.TensorProto] = _root_.scala.None
    }
    object Value {
      @SerialVersionUID(0L)
      case object Empty extends org.tensorflow.framework.summary.Summary.Value.Value {
        type ValueType = _root_.scala.Nothing
        override def isEmpty: _root_.scala.Boolean = true
        override def isDefined: _root_.scala.Boolean = false
        override def number: _root_.scala.Int = 0
        override def value: _root_.scala.Nothing = throw new java.util.NoSuchElementException("Empty.value")
      }
    
      @SerialVersionUID(0L)
      final case class SimpleValue(value: _root_.scala.Float) extends org.tensorflow.framework.summary.Summary.Value.Value {
        type ValueType = _root_.scala.Float
        override def isSimpleValue: _root_.scala.Boolean = true
        override def simpleValue: _root_.scala.Option[_root_.scala.Float] = Some(value)
        override def number: _root_.scala.Int = 2
      }
      @SerialVersionUID(0L)
      final case class ObsoleteOldStyleHistogram(value: _root_.com.google.protobuf.ByteString) extends org.tensorflow.framework.summary.Summary.Value.Value {
        type ValueType = _root_.com.google.protobuf.ByteString
        override def isObsoleteOldStyleHistogram: _root_.scala.Boolean = true
        override def obsoleteOldStyleHistogram: _root_.scala.Option[_root_.com.google.protobuf.ByteString] = Some(value)
        override def number: _root_.scala.Int = 3
      }
      @SerialVersionUID(0L)
      final case class Image(value: org.tensorflow.framework.summary.Summary.Image) extends org.tensorflow.framework.summary.Summary.Value.Value {
        type ValueType = org.tensorflow.framework.summary.Summary.Image
        override def isImage: _root_.scala.Boolean = true
        override def image: _root_.scala.Option[org.tensorflow.framework.summary.Summary.Image] = Some(value)
        override def number: _root_.scala.Int = 4
      }
      @SerialVersionUID(0L)
      final case class Histo(value: org.tensorflow.framework.histogram.HistogramProto) extends org.tensorflow.framework.summary.Summary.Value.Value {
        type ValueType = org.tensorflow.framework.histogram.HistogramProto
        override def isHisto: _root_.scala.Boolean = true
        override def histo: _root_.scala.Option[org.tensorflow.framework.histogram.HistogramProto] = Some(value)
        override def number: _root_.scala.Int = 5
      }
      @SerialVersionUID(0L)
      final case class Audio(value: org.tensorflow.framework.summary.Summary.Audio) extends org.tensorflow.framework.summary.Summary.Value.Value {
        type ValueType = org.tensorflow.framework.summary.Summary.Audio
        override def isAudio: _root_.scala.Boolean = true
        override def audio: _root_.scala.Option[org.tensorflow.framework.summary.Summary.Audio] = Some(value)
        override def number: _root_.scala.Int = 6
      }
      @SerialVersionUID(0L)
      final case class Tensor(value: org.tensorflow.framework.tensor.TensorProto) extends org.tensorflow.framework.summary.Summary.Value.Value {
        type ValueType = org.tensorflow.framework.tensor.TensorProto
        override def isTensor: _root_.scala.Boolean = true
        override def tensor: _root_.scala.Option[org.tensorflow.framework.tensor.TensorProto] = Some(value)
        override def number: _root_.scala.Int = 8
      }
    }
    implicit class ValueLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.summary.Summary.Value]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.summary.Summary.Value](_l) {
      def nodeName: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.nodeName)((c_, f_) => c_.copy(nodeName = f_))
      def tag: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Predef.String] = field(_.tag)((c_, f_) => c_.copy(tag = f_))
      def metadata: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.summary.SummaryMetadata] = field(_.getMetadata)((c_, f_) => c_.copy(metadata = _root_.scala.Option(f_)))
      def optionalMetadata: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[org.tensorflow.framework.summary.SummaryMetadata]] = field(_.metadata)((c_, f_) => c_.copy(metadata = f_))
      def simpleValue: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Float] = field(_.getSimpleValue)((c_, f_) => c_.copy(value = org.tensorflow.framework.summary.Summary.Value.Value.SimpleValue(f_)))
      def obsoleteOldStyleHistogram: _root_.scalapb.lenses.Lens[UpperPB, _root_.com.google.protobuf.ByteString] = field(_.getObsoleteOldStyleHistogram)((c_, f_) => c_.copy(value = org.tensorflow.framework.summary.Summary.Value.Value.ObsoleteOldStyleHistogram(f_)))
      def image: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.summary.Summary.Image] = field(_.getImage)((c_, f_) => c_.copy(value = org.tensorflow.framework.summary.Summary.Value.Value.Image(f_)))
      def histo: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.histogram.HistogramProto] = field(_.getHisto)((c_, f_) => c_.copy(value = org.tensorflow.framework.summary.Summary.Value.Value.Histo(f_)))
      def audio: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.summary.Summary.Audio] = field(_.getAudio)((c_, f_) => c_.copy(value = org.tensorflow.framework.summary.Summary.Value.Value.Audio(f_)))
      def tensor: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.tensor.TensorProto] = field(_.getTensor)((c_, f_) => c_.copy(value = org.tensorflow.framework.summary.Summary.Value.Value.Tensor(f_)))
      def value: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.summary.Summary.Value.Value] = field(_.value)((c_, f_) => c_.copy(value = f_))
    }
    final val NODE_NAME_FIELD_NUMBER = 7
    final val TAG_FIELD_NUMBER = 1
    final val METADATA_FIELD_NUMBER = 9
    final val SIMPLE_VALUE_FIELD_NUMBER = 2
    final val OBSOLETE_OLD_STYLE_HISTOGRAM_FIELD_NUMBER = 3
    final val IMAGE_FIELD_NUMBER = 4
    final val HISTO_FIELD_NUMBER = 5
    final val AUDIO_FIELD_NUMBER = 6
    final val TENSOR_FIELD_NUMBER = 8
    def of(
      nodeName: _root_.scala.Predef.String,
      tag: _root_.scala.Predef.String,
      metadata: _root_.scala.Option[org.tensorflow.framework.summary.SummaryMetadata],
      value: org.tensorflow.framework.summary.Summary.Value.Value
    ): _root_.org.tensorflow.framework.summary.Summary.Value = _root_.org.tensorflow.framework.summary.Summary.Value(
      nodeName,
      tag,
      metadata,
      value
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.Summary.Value])
  }
  
  implicit class SummaryLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.summary.Summary]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.summary.Summary](_l) {
    def value: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[org.tensorflow.framework.summary.Summary.Value]] = field(_.value)((c_, f_) => c_.copy(value = f_))
  }
  final val VALUE_FIELD_NUMBER = 1
  def of(
    value: _root_.scala.Seq[org.tensorflow.framework.summary.Summary.Value]
  ): _root_.org.tensorflow.framework.summary.Summary = _root_.org.tensorflow.framework.summary.Summary(
    value
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.Summary])
}
