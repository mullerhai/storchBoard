// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!

package org.tensorflow.framework.config

/** Options for a single Run() call.
  *
  * @param timeoutInMs
  *   Time to wait for operation to complete in milliseconds.
  * @param interOpThreadPool
  *   The thread pool to use, if session_inter_op_thread_pool is configured.
  *   To use the caller thread set this to -1 - this uses the caller thread
  *   to execute Session::Run() and thus avoids a context switch. Using the
  *   caller thread to execute Session::Run() should be done ONLY for simple
  *   graphs, where the overhead of an additional context switch is
  *   comparable with the overhead of Session::Run().
  * @param outputPartitionGraphs
  *   Whether the partition graph(s) executed by the executor(s) should be
  *   outputted via RunMetadata.
  * @param debugOptions
  *   EXPERIMENTAL.  Options used to initialize DebuggerState, if enabled.
  * @param reportTensorAllocationsUponOom
  *   When enabled, causes tensor allocation information to be included in
  *   the error message when the Run() call fails because the allocator ran
  *   out of memory (OOM).
  *  
  *   Enabling this option can slow down the Run() call.
  */
@SerialVersionUID(0L)
final case class RunOptions(
    traceLevel: org.tensorflow.framework.config.RunOptions.TraceLevel = org.tensorflow.framework.config.RunOptions.TraceLevel.NO_TRACE,
    timeoutInMs: _root_.scala.Long = 0L,
    interOpThreadPool: _root_.scala.Int = 0,
    outputPartitionGraphs: _root_.scala.Boolean = false,
    debugOptions: _root_.scala.Option[org.tensorflow.framework.debug.DebugOptions] = _root_.scala.None,
    reportTensorAllocationsUponOom: _root_.scala.Boolean = false,
    experimental: _root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental] = _root_.scala.None,
    unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[RunOptions] {
    @transient
    private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
    private[this] def __computeSerializedSize(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = traceLevel.value
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeEnumSize(1, __value)
        }
      };
      
      {
        val __value = timeoutInMs
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(2, __value)
        }
      };
      
      {
        val __value = interOpThreadPool
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(3, __value)
        }
      };
      
      {
        val __value = outputPartitionGraphs
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(5, __value)
        }
      };
      if (debugOptions.isDefined) {
        val __value = debugOptions.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      
      {
        val __value = reportTensorAllocationsUponOom
        if (__value != false) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(7, __value)
        }
      };
      if (experimental.isDefined) {
        val __value = experimental.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      __size += unknownFields.serializedSize
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var __size = __serializedSizeMemoized
      if (__size == 0) {
        __size = __computeSerializedSize() + 1
        __serializedSizeMemoized = __size
      }
      __size - 1
      
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = traceLevel.value
        if (__v != 0) {
          _output__.writeEnum(1, __v)
        }
      };
      {
        val __v = timeoutInMs
        if (__v != 0L) {
          _output__.writeInt64(2, __v)
        }
      };
      {
        val __v = interOpThreadPool
        if (__v != 0) {
          _output__.writeInt32(3, __v)
        }
      };
      {
        val __v = outputPartitionGraphs
        if (__v != false) {
          _output__.writeBool(5, __v)
        }
      };
      debugOptions.foreach { __v =>
        val __m = __v
        _output__.writeTag(6, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      {
        val __v = reportTensorAllocationsUponOom
        if (__v != false) {
          _output__.writeBool(7, __v)
        }
      };
      experimental.foreach { __v =>
        val __m = __v
        _output__.writeTag(8, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      unknownFields.writeTo(_output__)
    }
    def withTraceLevel(__v: org.tensorflow.framework.config.RunOptions.TraceLevel): RunOptions = copy(traceLevel = __v)
    def withTimeoutInMs(__v: _root_.scala.Long): RunOptions = copy(timeoutInMs = __v)
    def withInterOpThreadPool(__v: _root_.scala.Int): RunOptions = copy(interOpThreadPool = __v)
    def withOutputPartitionGraphs(__v: _root_.scala.Boolean): RunOptions = copy(outputPartitionGraphs = __v)
    def getDebugOptions: org.tensorflow.framework.debug.DebugOptions = debugOptions.getOrElse(org.tensorflow.framework.debug.DebugOptions.defaultInstance)
    def clearDebugOptions: RunOptions = copy(debugOptions = _root_.scala.None)
    def withDebugOptions(__v: org.tensorflow.framework.debug.DebugOptions): RunOptions = copy(debugOptions = Option(__v))
    def withReportTensorAllocationsUponOom(__v: _root_.scala.Boolean): RunOptions = copy(reportTensorAllocationsUponOom = __v)
    def getExperimental: org.tensorflow.framework.config.RunOptions.Experimental = experimental.getOrElse(org.tensorflow.framework.config.RunOptions.Experimental.defaultInstance)
    def clearExperimental: RunOptions = copy(experimental = _root_.scala.None)
    def withExperimental(__v: org.tensorflow.framework.config.RunOptions.Experimental): RunOptions = copy(experimental = Option(__v))
    def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
    def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = traceLevel.javaValueDescriptor
          if (__t.getNumber() != 0) __t else null
        }
        case 2 => {
          val __t = timeoutInMs
          if (__t != 0L) __t else null
        }
        case 3 => {
          val __t = interOpThreadPool
          if (__t != 0) __t else null
        }
        case 5 => {
          val __t = outputPartitionGraphs
          if (__t != false) __t else null
        }
        case 6 => debugOptions.orNull
        case 7 => {
          val __t = reportTensorAllocationsUponOom
          if (__t != false) __t else null
        }
        case 8 => experimental.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PEnum(traceLevel.scalaValueDescriptor)
        case 2 => _root_.scalapb.descriptors.PLong(timeoutInMs)
        case 3 => _root_.scalapb.descriptors.PInt(interOpThreadPool)
        case 5 => _root_.scalapb.descriptors.PBoolean(outputPartitionGraphs)
        case 6 => debugOptions.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 7 => _root_.scalapb.descriptors.PBoolean(reportTensorAllocationsUponOom)
        case 8 => experimental.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
    def companion: org.tensorflow.framework.config.RunOptions.type = org.tensorflow.framework.config.RunOptions
    // @@protoc_insertion_point(GeneratedMessage[tensorboard.RunOptions])
}

object RunOptions extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.config.RunOptions] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.config.RunOptions] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.config.RunOptions = {
    var __traceLevel: org.tensorflow.framework.config.RunOptions.TraceLevel = org.tensorflow.framework.config.RunOptions.TraceLevel.NO_TRACE
    var __timeoutInMs: _root_.scala.Long = 0L
    var __interOpThreadPool: _root_.scala.Int = 0
    var __outputPartitionGraphs: _root_.scala.Boolean = false
    var __debugOptions: _root_.scala.Option[org.tensorflow.framework.debug.DebugOptions] = _root_.scala.None
    var __reportTensorAllocationsUponOom: _root_.scala.Boolean = false
    var __experimental: _root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental] = _root_.scala.None
    var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __traceLevel = org.tensorflow.framework.config.RunOptions.TraceLevel.fromValue(_input__.readEnum())
        case 16 =>
          __timeoutInMs = _input__.readInt64()
        case 24 =>
          __interOpThreadPool = _input__.readInt32()
        case 40 =>
          __outputPartitionGraphs = _input__.readBool()
        case 50 =>
          __debugOptions = _root_.scala.Option(__debugOptions.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.debug.DebugOptions](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 56 =>
          __reportTensorAllocationsUponOom = _input__.readBool()
        case 66 =>
          __experimental = _root_.scala.Option(__experimental.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.config.RunOptions.Experimental](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case tag =>
          if (_unknownFields__ == null) {
            _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
          }
          _unknownFields__.parseField(tag, _input__)
      }
    }
    org.tensorflow.framework.config.RunOptions(
        traceLevel = __traceLevel,
        timeoutInMs = __timeoutInMs,
        interOpThreadPool = __interOpThreadPool,
        outputPartitionGraphs = __outputPartitionGraphs,
        debugOptions = __debugOptions,
        reportTensorAllocationsUponOom = __reportTensorAllocationsUponOom,
        experimental = __experimental,
        unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.config.RunOptions] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      org.tensorflow.framework.config.RunOptions(
        traceLevel = org.tensorflow.framework.config.RunOptions.TraceLevel.fromValue(__fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scalapb.descriptors.EnumValueDescriptor]).getOrElse(org.tensorflow.framework.config.RunOptions.TraceLevel.NO_TRACE.scalaValueDescriptor).number),
        timeoutInMs = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        interOpThreadPool = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        outputPartitionGraphs = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        debugOptions = __fieldsMap.get(scalaDescriptor.findFieldByNumber(6).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.debug.DebugOptions]]),
        reportTensorAllocationsUponOom = __fieldsMap.get(scalaDescriptor.findFieldByNumber(7).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
        experimental = __fieldsMap.get(scalaDescriptor.findFieldByNumber(8).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental]])
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.config.ConfigProtoCompanion.javaDescriptor.getMessageTypes().get(6)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.config.ConfigProtoCompanion.scalaDescriptor.messages(6)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?]= {
    var __out: _root_.scalapb.GeneratedMessageCompanion[?]= null
    (__number: @_root_.scala.unchecked) match {
      case 6 => __out = org.tensorflow.framework.debug.DebugOptions
      case 8 => __out = org.tensorflow.framework.config.RunOptions.Experimental
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] =
    Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]](
      _root_.org.tensorflow.framework.config.RunOptions.Experimental
    )
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?]= {
    (__fieldNumber: @_root_.scala.unchecked) match {
      case 1 => org.tensorflow.framework.config.RunOptions.TraceLevel
    }
  }
  lazy val defaultInstance = org.tensorflow.framework.config.RunOptions(
    traceLevel = org.tensorflow.framework.config.RunOptions.TraceLevel.NO_TRACE,
    timeoutInMs = 0L,
    interOpThreadPool = 0,
    outputPartitionGraphs = false,
    debugOptions = _root_.scala.None,
    reportTensorAllocationsUponOom = false,
    experimental = _root_.scala.None
  )
  /** TODO(pbar) Turn this into a TraceOptions proto which allows
    * tracing to be controlled in a more orthogonal manner?
    */
  sealed abstract class TraceLevel(val value: _root_.scala.Int) extends _root_.scalapb.GeneratedEnum {
    type EnumType = org.tensorflow.framework.config.RunOptions.TraceLevel
    type RecognizedType = org.tensorflow.framework.config.RunOptions.TraceLevel.Recognized
    def isNoTrace: _root_.scala.Boolean = false
    def isSoftwareTrace: _root_.scala.Boolean = false
    def isHardwareTrace: _root_.scala.Boolean = false
    def isFullTrace: _root_.scala.Boolean = false
    def companion: _root_.scalapb.GeneratedEnumCompanion[TraceLevel] = org.tensorflow.framework.config.RunOptions.TraceLevel
    final def asRecognized: _root_.scala.Option[org.tensorflow.framework.config.RunOptions.TraceLevel.Recognized] = if (isUnrecognized) _root_.scala.None else _root_.scala.Some(this.asInstanceOf[org.tensorflow.framework.config.RunOptions.TraceLevel.Recognized])
  }
  
  object TraceLevel extends _root_.scalapb.GeneratedEnumCompanion[TraceLevel] {
    sealed trait Recognized extends TraceLevel
    implicit def enumCompanion: _root_.scalapb.GeneratedEnumCompanion[TraceLevel] = this
    
    @SerialVersionUID(0L)
    case object NO_TRACE extends TraceLevel(0) with TraceLevel.Recognized {
      val index = 0
      val name = "NO_TRACE"
      override def isNoTrace: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    case object SOFTWARE_TRACE extends TraceLevel(1) with TraceLevel.Recognized {
      val index = 1
      val name = "SOFTWARE_TRACE"
      override def isSoftwareTrace: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    case object HARDWARE_TRACE extends TraceLevel(2) with TraceLevel.Recognized {
      val index = 2
      val name = "HARDWARE_TRACE"
      override def isHardwareTrace: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    case object FULL_TRACE extends TraceLevel(3) with TraceLevel.Recognized {
      val index = 3
      val name = "FULL_TRACE"
      override def isFullTrace: _root_.scala.Boolean = true
    }
    
    @SerialVersionUID(0L)
    final case class Unrecognized(unrecognizedValue: _root_.scala.Int) extends TraceLevel(unrecognizedValue) with _root_.scalapb.UnrecognizedEnum
    lazy val values: scala.collection.immutable.Seq[ValueType] = scala.collection.immutable.Seq(NO_TRACE, SOFTWARE_TRACE, HARDWARE_TRACE, FULL_TRACE)
    def fromValue(__value: _root_.scala.Int): TraceLevel = __value match {
      case 0 => NO_TRACE
      case 1 => SOFTWARE_TRACE
      case 2 => HARDWARE_TRACE
      case 3 => FULL_TRACE
      case __other => Unrecognized(__other)
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.EnumDescriptor = org.tensorflow.framework.config.RunOptions.javaDescriptor.getEnumTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.EnumDescriptor = org.tensorflow.framework.config.RunOptions.scalaDescriptor.enums(0)
  }
  /** Everything inside Experimental is subject to change and is not subject
    * to API stability guarantees in
    * https://www.tensorflow.org/guide/version_compat.
    *
    * @param collectiveGraphKey
    *   If non-zero, declares that this graph is going to use collective
    *   ops and must synchronize step_ids with any other graph with this
    *   same group_key value (in a distributed computation where tasks
    *   run disjoint graphs).
    * @param useRunHandlerPool
    *   If true, then operations (using the inter-op pool) across all
    *   session::run() calls will be centrally scheduled, optimizing for (median
    *   and tail) latency.
    *   Consider using this option for CPU-bound workloads like inference.
    */
  @SerialVersionUID(0L)
  final case class Experimental(
      collectiveGraphKey: _root_.scala.Long = 0L,
      useRunHandlerPool: _root_.scala.Boolean = false,
      runHandlerPoolOptions: _root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions] = _root_.scala.None,
      unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
      ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[Experimental] {
      @transient
      private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
      private[this] def __computeSerializedSize(): _root_.scala.Int = {
        var __size = 0
        
        {
          val __value = collectiveGraphKey
          if (__value != 0L) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(1, __value)
          }
        };
        
        {
          val __value = useRunHandlerPool
          if (__value != false) {
            __size += _root_.com.google.protobuf.CodedOutputStream.computeBoolSize(2, __value)
          }
        };
        if (runHandlerPoolOptions.isDefined) {
          val __value = runHandlerPoolOptions.get
          __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
        };
        __size += unknownFields.serializedSize
        __size
      }
      override def serializedSize: _root_.scala.Int = {
        var __size = __serializedSizeMemoized
        if (__size == 0) {
          __size = __computeSerializedSize() + 1
          __serializedSizeMemoized = __size
        }
        __size - 1
        
      }
      def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
        {
          val __v = collectiveGraphKey
          if (__v != 0L) {
            _output__.writeInt64(1, __v)
          }
        };
        {
          val __v = useRunHandlerPool
          if (__v != false) {
            _output__.writeBool(2, __v)
          }
        };
        runHandlerPoolOptions.foreach { __v =>
          val __m = __v
          _output__.writeTag(3, 2)
          _output__.writeUInt32NoTag(__m.serializedSize)
          __m.writeTo(_output__)
        };
        unknownFields.writeTo(_output__)
      }
      def withCollectiveGraphKey(__v: _root_.scala.Long): Experimental = copy(collectiveGraphKey = __v)
      def withUseRunHandlerPool(__v: _root_.scala.Boolean): Experimental = copy(useRunHandlerPool = __v)
      def getRunHandlerPoolOptions: org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions = runHandlerPoolOptions.getOrElse(org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions.defaultInstance)
      def clearRunHandlerPoolOptions: Experimental = copy(runHandlerPoolOptions = _root_.scala.None)
      def withRunHandlerPoolOptions(__v: org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions): Experimental = copy(runHandlerPoolOptions = Option(__v))
      def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
      def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
      def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
        (__fieldNumber: @_root_.scala.unchecked) match {
          case 1 => {
            val __t = collectiveGraphKey
            if (__t != 0L) __t else null
          }
          case 2 => {
            val __t = useRunHandlerPool
            if (__t != false) __t else null
          }
          case 3 => runHandlerPoolOptions.orNull
        }
      }
      def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
        _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
        (__field.number: @_root_.scala.unchecked) match {
          case 1 => _root_.scalapb.descriptors.PLong(collectiveGraphKey)
          case 2 => _root_.scalapb.descriptors.PBoolean(useRunHandlerPool)
          case 3 => runHandlerPoolOptions.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        }
      }
      def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
      def companion: org.tensorflow.framework.config.RunOptions.Experimental.type = org.tensorflow.framework.config.RunOptions.Experimental
      // @@protoc_insertion_point(GeneratedMessage[tensorboard.RunOptions.Experimental])
  }
  
  object Experimental extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.config.RunOptions.Experimental] {
    implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.config.RunOptions.Experimental] = this
    def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.config.RunOptions.Experimental = {
      var __collectiveGraphKey: _root_.scala.Long = 0L
      var __useRunHandlerPool: _root_.scala.Boolean = false
      var __runHandlerPoolOptions: _root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions] = _root_.scala.None
      var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
      var _done__ = false
      while (!_done__) {
        val _tag__ = _input__.readTag()
        _tag__ match {
          case 0 => _done__ = true
          case 8 =>
            __collectiveGraphKey = _input__.readInt64()
          case 16 =>
            __useRunHandlerPool = _input__.readBool()
          case 26 =>
            __runHandlerPoolOptions = _root_.scala.Option(__runHandlerPoolOptions.fold(_root_.scalapb.LiteParser.readMessage[org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
          case tag =>
            if (_unknownFields__ == null) {
              _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
            }
            _unknownFields__.parseField(tag, _input__)
        }
      }
      org.tensorflow.framework.config.RunOptions.Experimental(
          collectiveGraphKey = __collectiveGraphKey,
          useRunHandlerPool = __useRunHandlerPool,
          runHandlerPoolOptions = __runHandlerPoolOptions,
          unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
      )
    }
    implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.config.RunOptions.Experimental] = _root_.scalapb.descriptors.Reads{
      case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
        _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
        org.tensorflow.framework.config.RunOptions.Experimental(
          collectiveGraphKey = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
          useRunHandlerPool = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Boolean]).getOrElse(false),
          runHandlerPoolOptions = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).flatMap(_.as[_root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions]])
        )
      case _ => throw new RuntimeException("Expected PMessage")
    }
    def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.config.RunOptions.javaDescriptor.getNestedTypes().get(0)
    def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.config.RunOptions.scalaDescriptor.nestedMessages(0)
    def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?]= {
      var __out: _root_.scalapb.GeneratedMessageCompanion[?]= null
      (__number: @_root_.scala.unchecked) match {
        case 3 => __out = org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions
      }
      __out
    }
    lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] =
      Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]](
        _root_.org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions
      )
    def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?]= throw new MatchError(__fieldNumber)
    lazy val defaultInstance = org.tensorflow.framework.config.RunOptions.Experimental(
      collectiveGraphKey = 0L,
      useRunHandlerPool = false,
      runHandlerPoolOptions = _root_.scala.None
    )
    /** Options for run handler thread pool.
      *
      * @param priority
      *   Priority of the request. The run handler thread pool will schedule ops
      *   based on the priority number. The larger number means higher priority.
      */
    @SerialVersionUID(0L)
    final case class RunHandlerPoolOptions(
        priority: _root_.scala.Long = 0L,
        unknownFields: _root_.scalapb.UnknownFieldSet = _root_.scalapb.UnknownFieldSet.empty
        ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[RunHandlerPoolOptions] {
        @transient
        private[this] var __serializedSizeMemoized: _root_.scala.Int = 0
        private[this] def __computeSerializedSize(): _root_.scala.Int = {
          var __size = 0
          
          {
            val __value = priority
            if (__value != 0L) {
              __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(1, __value)
            }
          };
          __size += unknownFields.serializedSize
          __size
        }
        override def serializedSize: _root_.scala.Int = {
          var __size = __serializedSizeMemoized
          if (__size == 0) {
            __size = __computeSerializedSize() + 1
            __serializedSizeMemoized = __size
          }
          __size - 1
          
        }
        def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
          {
            val __v = priority
            if (__v != 0L) {
              _output__.writeInt64(1, __v)
            }
          };
          unknownFields.writeTo(_output__)
        }
        def withPriority(__v: _root_.scala.Long): RunHandlerPoolOptions = copy(priority = __v)
        def withUnknownFields(__v: _root_.scalapb.UnknownFieldSet) = copy(unknownFields = __v)
        def discardUnknownFields = copy(unknownFields = _root_.scalapb.UnknownFieldSet.empty)
        def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
          (__fieldNumber: @_root_.scala.unchecked) match {
            case 1 => {
              val __t = priority
              if (__t != 0L) __t else null
            }
          }
        }
        def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
          _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
          (__field.number: @_root_.scala.unchecked) match {
            case 1 => _root_.scalapb.descriptors.PLong(priority)
          }
        }
        def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToUnicodeString(this)
        def companion: org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions.type = org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions
        // @@protoc_insertion_point(GeneratedMessage[tensorboard.RunOptions.Experimental.RunHandlerPoolOptions])
    }
    
    object RunHandlerPoolOptions extends scalapb.GeneratedMessageCompanion[org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions] {
      implicit def messageCompanion: scalapb.GeneratedMessageCompanion[org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions] = this
      def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions = {
        var __priority: _root_.scala.Long = 0L
        var `_unknownFields__`: _root_.scalapb.UnknownFieldSet.Builder = null
        var _done__ = false
        while (!_done__) {
          val _tag__ = _input__.readTag()
          _tag__ match {
            case 0 => _done__ = true
            case 8 =>
              __priority = _input__.readInt64()
            case tag =>
              if (_unknownFields__ == null) {
                _unknownFields__ = new _root_.scalapb.UnknownFieldSet.Builder()
              }
              _unknownFields__.parseField(tag, _input__)
          }
        }
        org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions(
            priority = __priority,
            unknownFields = if (_unknownFields__ == null) _root_.scalapb.UnknownFieldSet.empty else _unknownFields__.result()
        )
      }
      implicit def messageReads: _root_.scalapb.descriptors.Reads[org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions] = _root_.scalapb.descriptors.Reads{
        case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
          _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
          org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions(
            priority = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Long]).getOrElse(0L)
          )
        case _ => throw new RuntimeException("Expected PMessage")
      }
      def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = org.tensorflow.framework.config.RunOptions.Experimental.javaDescriptor.getNestedTypes().get(0)
      def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = org.tensorflow.framework.config.RunOptions.Experimental.scalaDescriptor.nestedMessages(0)
      def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[?]= throw new MatchError(__number)
      lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[? <: _root_.scalapb.GeneratedMessage]] = Seq.empty
      def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[?]= throw new MatchError(__fieldNumber)
      lazy val defaultInstance = org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions(
        priority = 0L
      )
      implicit class RunHandlerPoolOptionsLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions](_l) {
        def priority: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.priority)((c_, f_) => c_.copy(priority = f_))
      }
      final val PRIORITY_FIELD_NUMBER = 1
      def of(
        priority: _root_.scala.Long
      ): _root_.org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions = _root_.org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions(
        priority
      )
      // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.RunOptions.Experimental.RunHandlerPoolOptions])
    }
    
    implicit class ExperimentalLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.config.RunOptions.Experimental]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.config.RunOptions.Experimental](_l) {
      def collectiveGraphKey: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.collectiveGraphKey)((c_, f_) => c_.copy(collectiveGraphKey = f_))
      def useRunHandlerPool: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.useRunHandlerPool)((c_, f_) => c_.copy(useRunHandlerPool = f_))
      def runHandlerPoolOptions: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions] = field(_.getRunHandlerPoolOptions)((c_, f_) => c_.copy(runHandlerPoolOptions = _root_.scala.Option(f_)))
      def optionalRunHandlerPoolOptions: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions]] = field(_.runHandlerPoolOptions)((c_, f_) => c_.copy(runHandlerPoolOptions = f_))
    }
    final val COLLECTIVE_GRAPH_KEY_FIELD_NUMBER = 1
    final val USE_RUN_HANDLER_POOL_FIELD_NUMBER = 2
    final val RUN_HANDLER_POOL_OPTIONS_FIELD_NUMBER = 3
    def of(
      collectiveGraphKey: _root_.scala.Long,
      useRunHandlerPool: _root_.scala.Boolean,
      runHandlerPoolOptions: _root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental.RunHandlerPoolOptions]
    ): _root_.org.tensorflow.framework.config.RunOptions.Experimental = _root_.org.tensorflow.framework.config.RunOptions.Experimental(
      collectiveGraphKey,
      useRunHandlerPool,
      runHandlerPoolOptions
    )
    // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.RunOptions.Experimental])
  }
  
  implicit class RunOptionsLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.config.RunOptions]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, org.tensorflow.framework.config.RunOptions](_l) {
    def traceLevel: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.config.RunOptions.TraceLevel] = field(_.traceLevel)((c_, f_) => c_.copy(traceLevel = f_))
    def timeoutInMs: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.timeoutInMs)((c_, f_) => c_.copy(timeoutInMs = f_))
    def interOpThreadPool: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.interOpThreadPool)((c_, f_) => c_.copy(interOpThreadPool = f_))
    def outputPartitionGraphs: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.outputPartitionGraphs)((c_, f_) => c_.copy(outputPartitionGraphs = f_))
    def debugOptions: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.debug.DebugOptions] = field(_.getDebugOptions)((c_, f_) => c_.copy(debugOptions = _root_.scala.Option(f_)))
    def optionalDebugOptions: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[org.tensorflow.framework.debug.DebugOptions]] = field(_.debugOptions)((c_, f_) => c_.copy(debugOptions = f_))
    def reportTensorAllocationsUponOom: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Boolean] = field(_.reportTensorAllocationsUponOom)((c_, f_) => c_.copy(reportTensorAllocationsUponOom = f_))
    def experimental: _root_.scalapb.lenses.Lens[UpperPB, org.tensorflow.framework.config.RunOptions.Experimental] = field(_.getExperimental)((c_, f_) => c_.copy(experimental = _root_.scala.Option(f_)))
    def optionalExperimental: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental]] = field(_.experimental)((c_, f_) => c_.copy(experimental = f_))
  }
  final val TRACE_LEVEL_FIELD_NUMBER = 1
  final val TIMEOUT_IN_MS_FIELD_NUMBER = 2
  final val INTER_OP_THREAD_POOL_FIELD_NUMBER = 3
  final val OUTPUT_PARTITION_GRAPHS_FIELD_NUMBER = 5
  final val DEBUG_OPTIONS_FIELD_NUMBER = 6
  final val REPORT_TENSOR_ALLOCATIONS_UPON_OOM_FIELD_NUMBER = 7
  final val EXPERIMENTAL_FIELD_NUMBER = 8
  def of(
    traceLevel: org.tensorflow.framework.config.RunOptions.TraceLevel,
    timeoutInMs: _root_.scala.Long,
    interOpThreadPool: _root_.scala.Int,
    outputPartitionGraphs: _root_.scala.Boolean,
    debugOptions: _root_.scala.Option[org.tensorflow.framework.debug.DebugOptions],
    reportTensorAllocationsUponOom: _root_.scala.Boolean,
    experimental: _root_.scala.Option[org.tensorflow.framework.config.RunOptions.Experimental]
  ): _root_.org.tensorflow.framework.config.RunOptions = _root_.org.tensorflow.framework.config.RunOptions(
    traceLevel,
    timeoutInMs,
    interOpThreadPool,
    outputPartitionGraphs,
    debugOptions,
    reportTensorAllocationsUponOom,
    experimental
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[tensorboard.RunOptions])
}
